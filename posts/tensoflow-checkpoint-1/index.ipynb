{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-checkpoint.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "nikola": {
      "category": "Tensorflow",
      "date": "2019-12-17 11:39:01 UTC-08:00",
      "description": "Tensorflow Checkpoint Exploration",
      "link": "",
      "slug": "tensoflow-checkpoint-1",
      "tags": "tensorflow",
      "title": "Comparing TF Checkpoints in v1.x and v2.x",
      "type": "text"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eMC7y2wuvaCG"
      },
      "source": [
        "# Comparing TF Checkpoints in v1.x and v2.x\n",
        "\n",
        "## Outline\n",
        "\n",
        "+ How to create a checkpoint?\n",
        "+ What checkpoint looks like?\n",
        "\n",
        "<!-- TEASER_END -->\n",
        "## Creating a checkpoint\n",
        "\n",
        "First, we create the basic LeNet-5 with MNIST as [we did previously](https://jiayiliu.github.io/posts/tensoflow-lite-convertor/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "-xbFEmyuxEI3",
        "outputId": "67ebf180-1fcb-40f8-ff52-ddc0e391d15b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'2.1.0-rc1'"
            ]
          },
          "execution_count": 1,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf2\n",
        "import tensorflow.compat.v1 as tf1\n",
        "# comment out the following lines for tf2 example, restart runtime\n",
        "#tf1.disable_eager_execution()\n",
        "\n",
        "tf2.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "D3Hw1wyxugvV"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(10000, 28,28, 1).astype('float32') / 255\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "keras.backend.clear_session()\n",
        "def get_model():\n",
        "  model = keras.Sequential([\n",
        "                       keras.layers.Conv2D(16, 3, activation='relu', input_shape=(28,28,1)),\n",
        "                       keras.layers.BatchNormalization(),\n",
        "                       keras.layers.MaxPool2D(),\n",
        "                       keras.layers.Conv2D(16, 3, activation='relu'),\n",
        "                       keras.layers.BatchNormalization(),\n",
        "                       keras.layers.MaxPool2D(),\n",
        "                       keras.layers.Flatten(),\n",
        "                       keras.layers.Dense(128, activation='relu'),\n",
        "                       keras.layers.Dense(10, activation='softmax', )\n",
        "  ])\n",
        "\n",
        "  opt = keras.optimizers.Adam()\n",
        "  model.compile(optimizer=opt,\n",
        "          loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "          metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "  return model, opt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fl6GO-pa4XcK"
      },
      "source": [
        "+ **TF v1.x** we create the checkpoint based on the [TF doc v1](https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/Checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "colab_type": "code",
        "id": "2SBA2U17wIfv",
        "outputId": "9732d57b-00b4-4004-965f-dbd8e3f4c644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove './tf_ckpt/*': No such file or directory\n",
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 60000 samples\n",
            "60000/60000 [==============================] - 33s 548us/sample - loss: 0.1790 - sparse_categorical_accuracy: 0.9449\n",
            "Train on 60000 samples\n",
            "60000/60000 [==============================] - 32s 534us/sample - loss: 0.0484 - sparse_categorical_accuracy: 0.9847\n"
          ]
        }
      ],
      "source": [
        "!rm ./tf_ckpt/*\n",
        "m, opt = get_model()\n",
        "saver = tf1.train.Saver()\n",
        "with tf1.Session() as sess:\n",
        "  for i in range(2):\n",
        "    m.fit(x_train, y_train, batch_size=128)\n",
        "    saver.save(sess, \"./tf_ckpt/model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "colab_type": "code",
        "id": "1VnV5Ayj660G",
        "outputId": "0a4dc48e-0c8f-41bc-a871-9ac556f1ee99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 396K\n",
            "-rw-r--r-- 1 root root   67 Dec 18 03:31 checkpoint\n",
            "-rw-r--r-- 1 root root 216K Dec 18 03:31 model.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root  629 Dec 18 03:31 model.index\n",
            "-rw-r--r-- 1 root root 172K Dec 18 03:31 model.meta\n"
          ]
        }
      ],
      "source": [
        "!ls -lh ./tf_ckpt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "WT_5_PvGBoXD",
        "outputId": "77d42859-d3f9-4bc2-9d44-ef8e8551389f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_checkpoint_path: \"model\"\n",
            "all_model_checkpoint_paths: \"model\"\n"
          ]
        }
      ],
      "source": [
        "!cat ./tf_ckpt/checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mLKfAiYjxgzB"
      },
      "source": [
        "+ **TF v2.x**, we create the checkpoint related properties (see [tf doc](https://www.tensorflow.org/guide/checkpoint)).  However, to simplify the process, we don't use the confusing `tf.GradientTape`.  Keep it simple, we just use `model.fit` from keras.  *Need to restart and comment out `disable_eager_execution`*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "WONuFsbiw8QQ",
        "outputId": "dad165d6-8afc-401f-ed7c-e8cf76453e5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'tf_ckpt_v2/*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm tf_ckpt_v2/*\n",
        "keras.backend.clear_session()\n",
        "m, opt = get_model()\n",
        "ckpt = tf2.train.Checkpoint(step=tf2.Variable(1), optimizer=opt, net=m)\n",
        "manager = tf2.train.CheckpointManager(ckpt, './tf_ckpt_v2', max_to_keep=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "colab_type": "code",
        "id": "1ib0kCmIxYkm",
        "outputId": "23e962d8-2154-4c7a-98b6-5d8b2ab30537"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "60000/60000 [==============================] - 32s 540us/sample - loss: 0.1831 - sparse_categorical_accuracy: 0.9452\n",
            "Saved checkpoint for step 2: ./tf_ckpt_v2/ckpt-1\n",
            "Train on 60000 samples\n",
            "60000/60000 [==============================] - 32s 539us/sample - loss: 0.0466 - sparse_categorical_accuracy: 0.9857\n",
            "Saved checkpoint for step 3: ./tf_ckpt_v2/ckpt-2\n"
          ]
        }
      ],
      "source": [
        "ckpt.restore(manager.latest_checkpoint)\n",
        "for i in range(2):\n",
        "  m.fit(x_train, y_train, batch_size=128)\n",
        "  ckpt.step.assign_add(1)\n",
        "  save_path = manager.save()\n",
        "  print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "colab_type": "code",
        "id": "noYT3P-6yByi",
        "outputId": "8d70f4f3-253f-4157-abdb-29ef8fbc9e46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 1.3M\n",
            "-rw-r--r-- 1 root root  254 Dec 18 03:35 checkpoint\n",
            "-rw-r--r-- 1 root root 653K Dec 18 03:34 ckpt-1.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root 3.1K Dec 18 03:34 ckpt-1.index\n",
            "-rw-r--r-- 1 root root 653K Dec 18 03:35 ckpt-2.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root 3.1K Dec 18 03:35 ckpt-2.index\n"
          ]
        }
      ],
      "source": [
        "!ls -lh ./tf_ckpt_v2/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "colab_type": "code",
        "id": "_SzjQ_nlBteI",
        "outputId": "f0819dbf-6675-40ec-b65c-c0fdbe19d95a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_checkpoint_path: \"ckpt-2\"\n",
            "all_model_checkpoint_paths: \"ckpt-1\"\n",
            "all_model_checkpoint_paths: \"ckpt-2\"\n",
            "all_model_checkpoint_timestamps: 1576640070.138009\n",
            "all_model_checkpoint_timestamps: 1576640102.5460615\n",
            "last_preserved_timestamp: 1576640036.6357675\n"
          ]
        }
      ],
      "source": [
        "!cat ./tf_ckpt_v2/checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SZfC0SS_2deK"
      },
      "source": [
        "## Differences between 1.x and 2.x\n",
        "\n",
        "In TF 1.x versions, the checkpoint contains four file types ([excerpt](https://stackoverflow.com/questions/41265035/tensorflow-why-there-are-3-files-after-saving-the-model)):\n",
        "\n",
        "+ `checkpoint`: checkpoint path index\n",
        "+ `*.index`: it is a string-string immutable table(`tensorflow::table::Table`). Each key is a name of a tensor and its value is a serialized `BundleEntryProto`. Each `BundleEntryProto` describes the metadata of a tensor: which of the \"data\" files contains the content of a tensor, the offset into that file, checksum, some auxiliary data, etc.\n",
        "+ `*.data-*-of*`: it is TensorBundle collection, save the values of all variables.\n",
        "+ `*.meta`: describes the saved graph structure, includes `GraphDef`, `SaverDef`, and so on; then apply `tf.train.import_meta_graph('/tmp/model.ckpt.meta')`, will restore Saver and Graph.\n",
        "\n",
        "In TF2.x versions, the `meta` file is missing, in line with removing the `session` and `graph`.  Based on [TF doc](https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint?version=stable):\n",
        "\n",
        "  Checkpoint.save and Checkpoint.restore write and read object-based checkpoints, in contrast to TensorFlow 1.x's tf.compat.v1.train.Saver which writes and reads variable.name based checkpoints. Object-based checkpointing saves a graph of dependencies between Python objects (Layers, Optimizers, Variables, etc.) with named edges, and this graph is used to match variables when restoring a checkpoint. It can be more robust to changes in the Python program, and helps to support restore-on-create for variables.",
	"\n",
        "## Future post\n",
        "\n",
        "+ How to restore from a checkpoint?\n",
        "+ Investigate checkpoint with graph/node."

      ]
    }
  ]
}