<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
fb: http://ogp.me/ns/fb# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Tensorflow Lite Conversion Exploration">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>TensorFlow Lite Conversion | Lab of Random</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../../rss.xml">
<link rel="canonical" href="https://jiayiliu.github.com/posts/tensoflow-lite-convertor/">
<meta property="fb:app_id" content="321809675046639">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Jiayi (Jason) Liu">
<link rel="prev" href="../imagenet-benchmark/" title="ImageNet Challenge Benchmark" type="text/html">
<link rel="next" href="../pocketflow-intro/" title="PocketFlow unofficial guide" type="text/html">
<meta property="og:site_name" content="Lab of Random">
<meta property="og:title" content="TensorFlow Lite Conversion">
<meta property="og:url" content="https://jiayiliu.github.com/posts/tensoflow-lite-convertor/">
<meta property="og:description" content="Tensorflow Lite Conversion Exploration">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2019-10-29T05:39:01-08:00">
<meta property="article:tag" content="compression">
<meta property="article:tag" content="lite">
<meta property="article:tag" content="tensorflow">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="../../">

            <span id="blog-title">Lab of Random</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../../categories/" class="nav-link">Tags</a>
                </li>
<li class="nav-item">
<a href="../../rss.xml" class="nav-link">RSS feed</a>
                </li>
<li class="nav-item">
<a href="https://colab.research.google.com/github/jiayiliu/jiayiliu.github.io/blob/src/posts/index.ipynb" class="nav-link">Google Colab</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right">
<li class="nav-item">
    <a href="index.ipynb" id="sourcelink" class="nav-link">Source</a>
    </li>


                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">TensorFlow Lite Conversion</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Jiayi (Jason) Liu
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2019-10-29T05:39:01-08:00" itemprop="datePublished" title="2019-10-29 05:39">2019-10-29 05:39</time></a>
            </p>
                <p class="commentline">
        
<span class="fb-comments-count" data-url="/posts/tensoflow-lite-convertor/">


            
        <p class="sourceline"><a href="index.ipynb" class="sourcelink">Source</a></p>

        </span></p>
</div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="TF-Lite-Conversion-Comparison">TF Lite Conversion Comparison<a class="anchor-link" href="#TF-Lite-Conversion-Comparison">¶</a>
</h2>
<p>This page provide a guidance of using TFLite to convert and deploy models.</p>
<p>We use LeNet-like CNN model on MNIST dataset.  The workflow is general, however the performance of TF Lite model (compression, accuracy) would be different based your models and datasets.</p>
<p><!-- TEASER_END -->
Specifically, I am going to explain the workflow buried in Tensorflow Lite webpage</p>
<p><img src="https://www.tensorflow.org/lite/performance/images/optimization.jpg" alt="Lite convert decision map"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># !pip install -U tensorflow=2.0.0</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>rm -rf *.tflite
<span class="o">!</span>mkdir -p tmp
<span class="o">!</span>rm -rf tmp/*.tflite
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">tensorflow_version</span> 1.15
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">files</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">lite</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">packaging</span> <span class="kn">import</span> <span class="n">version</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">path</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">IPython.core.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"TF_CPP_MIN_LOG_LEVEL"</span><span class="p">]</span><span class="o">=</span><span class="s2">"3"</span>
<span class="n">ver1_flag</span> <span class="o">=</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">version</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="s2">"2.0"</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>`%tensorflow_version` only switches the major version: `1.x` or `2.x`.
You set: `1.15`. This will be interpreted as: `1.x`.


TensorFlow 1.x selected.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[0]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>'1.15.0'</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-data">Load data<a class="anchor-link" href="#Load-data">¶</a>
</h2>
<p>Also we create two generator functions, <code>create_data</code> and <code>create_represent_data</code> for TFLite usage later.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># load mnist data for testing</span>

<span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">60000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_data</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">data_gen</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
      <span class="k">yield</span> <span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">data_gen</span>

<span class="k">def</span> <span class="nf">create_represent_data</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">data_gen</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
      <span class="k">yield</span> <span class="p">[</span><span class="nb">list</span><span class="p">([</span><span class="n">i</span><span class="p">])]</span>
  <span class="k">return</span> <span class="n">data_gen</span>

<span class="n">x_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[0]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(60000, 28, 28, 1)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-Keras-Model">Build Keras Model<a class="anchor-link" href="#Build-Keras-Model">¶</a>
</h2>
<p>We build a simple CNN model for testing.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
                       <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">1</span><span class="p">)),</span>
                       <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
                       <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(),</span>
                       <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
                       <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
                       <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">(),</span>
                       <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
                       <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
                       <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">,</span> <span class="p">)</span>
<span class="p">])</span>

<span class="n">m</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
          <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(),</span>
          <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="s2">"model.h5"</span><span class="p">):</span>  <span class="c1"># try to avoid train again, load model if present</span>
  <span class="n">m</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.h5"</span><span class="p">)</span>
  <span class="n">m</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(),</span>
          <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(),</span>
          <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()])</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">m</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
  <span class="n">m</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"model.h5"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 60000 samples
Epoch 1/10
60000/60000 [==============================] - 39s 647us/sample - loss: 0.1670 - sparse_categorical_accuracy: 0.9497
Epoch 2/10
60000/60000 [==============================] - 37s 622us/sample - loss: 0.0486 - sparse_categorical_accuracy: 0.9854
Epoch 3/10
60000/60000 [==============================] - 37s 622us/sample - loss: 0.0328 - sparse_categorical_accuracy: 0.9900
Epoch 4/10
60000/60000 [==============================] - 40s 663us/sample - loss: 0.0237 - sparse_categorical_accuracy: 0.9926
Epoch 5/10
60000/60000 [==============================] - 39s 652us/sample - loss: 0.0188 - sparse_categorical_accuracy: 0.9940
Epoch 6/10
60000/60000 [==============================] - 39s 652us/sample - loss: 0.0123 - sparse_categorical_accuracy: 0.9961
Epoch 7/10
60000/60000 [==============================] - 39s 655us/sample - loss: 0.0125 - sparse_categorical_accuracy: 0.9959
Epoch 8/10
60000/60000 [==============================] - 39s 655us/sample - loss: 0.0087 - sparse_categorical_accuracy: 0.9974
Epoch 9/10
60000/60000 [==============================] - 39s 657us/sample - loss: 0.0081 - sparse_categorical_accuracy: 0.9974
Epoch 10/10
60000/60000 [==============================] - 39s 656us/sample - loss: 0.0068 - sparse_categorical_accuracy: 0.9976
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="c1">## accuracy</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>10000/10000 [==============================] - 3s 289us/sample - loss: 0.0532 - sparse_categorical_accuracy: 0.9867
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[0]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9867</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">"model.h5"</span><span class="p">)</span>
<span class="n">plain_res</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">plain_res</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[0]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>(10000, 10)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">plain_res</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>  <span class="c1"># test accuracy</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[0]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>0.9867</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TF-Lite-conversion-options">TF Lite conversion options<a class="anchor-link" href="#TF-Lite-conversion-options">¶</a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_conv</span><span class="p">(</span><span class="n">model_file</span><span class="p">):</span>  <span class="c1"># create tflite converter for keras model</span>
  <span class="sd">"""</span>
<span class="sd">  Create TFLiteConverter from keras model</span>
<span class="sd">  """</span>
  <span class="k">if</span> <span class="n">ver1_flag</span><span class="p">:</span>
    <span class="n">conv</span> <span class="o">=</span> <span class="n">lite</span><span class="o">.</span><span class="n">TFLiteConverter</span><span class="o">.</span><span class="n">from_keras_model_file</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span> 
    <span class="n">m</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
    <span class="n">conv</span> <span class="o">=</span> <span class="n">lite</span><span class="o">.</span><span class="n">TFLiteConverter</span><span class="o">.</span><span class="n">from_keras_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">conv</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_diff</span><span class="p">(</span><span class="n">result1</span><span class="p">,</span> <span class="n">result2</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  compute the difference between two results</span>
<span class="sd">  """</span>
  <span class="k">assert</span> <span class="n">result1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">result2</span><span class="o">.</span><span class="n">shape</span>
  <span class="n">id1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">result1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">id2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">result2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">mismatch</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">id1</span><span class="o">!=</span><span class="n">id2</span><span class="p">)</span>
  <span class="n">diff</span> <span class="o">=</span> <span class="n">result1</span><span class="p">[</span><span class="n">id1</span><span class="p">]</span><span class="o">-</span><span class="n">result2</span><span class="p">[</span><span class="n">id1</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">mismatch</span><span class="p">,</span> <span class="n">diff</span>

<span class="k">def</span> <span class="nf">get_res</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">data_gen</span><span class="p">):</span>  <span class="c1"># get interpreter output</span>
  <span class="sd">"""</span>
<span class="sd">  get output from tflite model</span>
<span class="sd">  </span>
<span class="sd">  filename - tflite model</span>
<span class="sd">  data_gen - generator for data input x</span>
<span class="sd">  """</span>
  <span class="n">intp</span> <span class="o">=</span> <span class="n">lite</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
  <span class="n">intp</span><span class="o">.</span><span class="n">allocate_tensors</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data_gen</span><span class="p">():</span>
    <span class="n">intp</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="n">intp</span><span class="o">.</span><span class="n">get_input_details</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'index'</span><span class="p">],</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">intp</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>
    <span class="k">yield</span> <span class="n">intp</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">intp</span><span class="o">.</span><span class="n">get_output_details</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'index'</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">get_acc</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
  <span class="s2">"get acuracy from tflite model"</span>
  <span class="n">data_gen</span> <span class="o">=</span> <span class="n">create_data</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">get_res</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">data_gen</span><span class="p">)])</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_res2</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">data_gen</span><span class="p">):</span>
  <span class="s2">"get accuracy and time"</span>
  <span class="n">intp</span> <span class="o">=</span> <span class="n">lite</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
  <span class="n">intp</span><span class="o">.</span><span class="n">allocate_tensors</span><span class="p">()</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data_gen</span><span class="p">():</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span>
    <span class="n">intp</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="n">intp</span><span class="o">.</span><span class="n">get_input_details</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'index'</span><span class="p">],</span> <span class="n">i</span><span class="p">)</span>
    <span class="n">intp</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">monotonic</span><span class="p">()</span> <span class="o">-</span> <span class="n">t</span>
    <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">intp</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="n">intp</span><span class="o">.</span><span class="n">get_output_details</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'index'</span><span class="p">])),</span> <span class="n">t</span>


<span class="k">def</span> <span class="nf">get_acc_and_time</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
  <span class="n">data_gen</span> <span class="o">=</span> <span class="n">create_data</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
  <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">get_res2</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">data_gen</span><span class="p">)])</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pred</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">y_test</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pred</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">pred</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># acc, mean, std of inference</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Collect-all-options-for-tflite-conversion">Collect <em>all</em> options for tflite conversion<a class="anchor-link" href="#Collect-all-options-for-tflite-conversion">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># for converter.target_spec.supported_types </span>
<span class="n">type_choice</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">if</span> <span class="n">ver1_flag</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">lite</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="n">__all__</span><span class="p">:</span>
        <span class="n">type_choice</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">lower</span><span class="p">()]</span> <span class="o">=</span> <span class="p">[</span><span class="n">lite</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">tensorflow.lite.python</span> <span class="kn">import</span> <span class="n">lite_constants</span> <span class="k">as</span> <span class="n">constants</span>
    <span class="n">type_choice</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"float"</span><span class="p">:</span> <span class="p">[</span><span class="n">constants</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">],</span>      <span class="c1"># tf.float32</span>
        <span class="s2">"int8"</span><span class="p">:</span> <span class="p">[</span><span class="n">constants</span><span class="o">.</span><span class="n">INT8</span><span class="p">],</span>        <span class="c1"># tf.int8</span>
        <span class="s2">"int32"</span><span class="p">:</span> <span class="p">[</span><span class="n">constants</span><span class="o">.</span><span class="n">INT32</span><span class="p">],</span>      <span class="c1"># tf.int32</span>
        <span class="s2">"int64"</span><span class="p">:</span> <span class="p">[</span><span class="n">constants</span><span class="o">.</span><span class="n">INT64</span><span class="p">],</span>      <span class="c1"># tf.int64</span>
        <span class="s2">"string"</span><span class="p">:</span> <span class="p">[</span><span class="n">constants</span><span class="o">.</span><span class="n">STRING</span><span class="p">],</span>    <span class="c1"># tf.string</span>
        <span class="s2">"uint8"</span><span class="p">:</span> <span class="p">[</span><span class="n">constants</span><span class="o">.</span><span class="n">QUANTIZED_UINT8</span><span class="p">],</span>  <span class="c1">#tf.uint</span>
    <span class="p">}</span>
<span class="n">type_choice</span><span class="p">[</span><span class="s1">'none'</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>   
<span class="c1"># for converter.target_spec.supported_ops</span>
<span class="n">ops_choice</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"int8"</span><span class="p">:</span> <span class="p">[</span><span class="n">lite</span><span class="o">.</span><span class="n">OpsSet</span><span class="o">.</span><span class="n">TFLITE_BUILTINS_INT8</span><span class="p">],</span>
    <span class="s2">"tflite"</span><span class="p">:</span> <span class="p">[</span><span class="n">lite</span><span class="o">.</span><span class="n">OpsSet</span><span class="o">.</span><span class="n">TFLITE_BUILTINS</span><span class="p">],</span>  <span class="c1"># default</span>
    <span class="s2">"tf"</span><span class="p">:</span> <span class="p">[</span><span class="n">lite</span><span class="o">.</span><span class="n">OpsSet</span><span class="o">.</span><span class="n">SELECT_TF_OPS</span><span class="p">,</span> <span class="n">lite</span><span class="o">.</span><span class="n">OpsSet</span><span class="o">.</span><span class="n">TFLITE_BUILTINS</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">opt_choice</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"default"</span><span class="p">:</span> <span class="p">[</span><span class="n">lite</span><span class="o">.</span><span class="n">Optimize</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">],</span> 
    <span class="s2">"latency"</span><span class="p">:</span> <span class="p">[</span><span class="n">lite</span><span class="o">.</span><span class="n">Optimize</span><span class="o">.</span><span class="n">OPTIMIZE_FOR_LATENCY</span><span class="p">],</span> 
    <span class="s2">"size"</span><span class="p">:</span> <span class="p">[</span><span class="n">lite</span><span class="o">.</span><span class="n">Optimize</span><span class="o">.</span><span class="n">OPTIMIZE_FOR_SIZE</span><span class="p">],</span>
    <span class="s2">"none"</span><span class="p">:</span> <span class="p">[]</span>
<span class="p">}</span>

<span class="c1"># for converter.representative_dataset</span>
<span class="n">data_gen2</span> <span class="o">=</span> <span class="n">create_represent_data</span><span class="p">(</span><span class="n">x_train</span><span class="p">[:</span><span class="mi">5000</span><span class="p">])</span>
<span class="n">data_choice</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"with_data"</span><span class="p">:</span> <span class="n">data_gen2</span><span class="p">,</span> <span class="s2">"wo_data"</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">type_choice</span>
<span class="c1"># tflite and graphviz_dot are used to control output graph type.</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[0]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>{'float': [tf.float32],
 'float16': [tf.float16],
 'graphviz_dot': [3],
 'int32': [tf.int32],
 'int64': [tf.int64],
 'int8': [tf.int8],
 'none': None,
 'quantized_uint8': [tf.uint8],
 'string': [tf.string],
 'tflite': [2]}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [ ]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%capture</span> convert_log 
<span class="c1"># output has been cleared</span>
<span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">xdata</span> <span class="ow">in</span> <span class="n">data_choice</span><span class="p">:</span>
  <span class="k">for</span> <span class="n">xopt</span> <span class="ow">in</span> <span class="n">opt_choice</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">xops</span> <span class="ow">in</span> <span class="n">ops_choice</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">xtype</span> <span class="ow">in</span> <span class="n">type_choice</span><span class="p">:</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="s2">"tmp/</span><span class="si">%s</span><span class="s2">-opt(</span><span class="si">%s</span><span class="s2">)-ops(</span><span class="si">%s</span><span class="s2">)-type(</span><span class="si">%s</span><span class="s2">).tflite"</span><span class="o">%</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">xops</span><span class="p">,</span> <span class="n">xtype</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"********  </span><span class="si">%s</span><span class="s2"> ********"</span> <span class="o">%</span> <span class="n">filename</span><span class="p">)</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
        <span class="k">try</span><span class="p">:</span>
          <span class="n">conv</span> <span class="o">=</span> <span class="n">get_conv</span><span class="p">(</span><span class="s2">"model.h5"</span><span class="p">)</span>
          <span class="n">conv</span><span class="o">.</span><span class="n">optimizations</span> <span class="o">=</span> <span class="n">opt_choice</span><span class="p">[</span><span class="n">xopt</span><span class="p">]</span>
          <span class="n">conv</span><span class="o">.</span><span class="n">representative_dataset</span> <span class="o">=</span> <span class="n">data_choice</span><span class="p">[</span><span class="n">xdata</span><span class="p">]</span>
          <span class="n">conv</span><span class="o">.</span><span class="n">target_spec</span><span class="o">.</span><span class="n">supported_ops</span> <span class="o">=</span> <span class="n">ops_choice</span><span class="p">[</span><span class="n">xops</span><span class="p">]</span>
          <span class="n">conv</span><span class="o">.</span><span class="n">target_spec</span><span class="o">.</span><span class="n">supported_types</span> <span class="o">=</span> <span class="n">type_choice</span><span class="p">[</span><span class="n">xtype</span><span class="p">]</span>
          <span class="n">fb</span> <span class="o">=</span> <span class="n">conv</span><span class="o">.</span><span class="n">convert</span><span class="p">()</span>
          <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"success"</span><span class="p">)</span>
          <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">fb</span><span class="p">)</span>
          <span class="n">size</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">getsize</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
          <span class="nb">print</span><span class="p">(</span><span class="s2">"finished"</span><span class="p">)</span>
          <span class="n">acc</span> <span class="o">=</span> <span class="n">get_acc_and_time</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
          <span class="n">msg</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="fm">__str__</span><span class="p">()</span>
          <span class="nb">print</span><span class="p">(</span><span class="s2">"failed - </span><span class="si">%s</span><span class="s2">"</span><span class="o">%</span><span class="n">msg</span><span class="p">)</span>    
          <span class="n">size</span> <span class="o">=</span> <span class="kc">None</span>
          <span class="n">acc</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">finally</span><span class="p">:</span>
          <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">xdata</span><span class="p">,</span> <span class="n">xopt</span><span class="p">,</span> <span class="n">xops</span><span class="p">,</span> <span class="n">xtype</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">msg</span><span class="p">,</span> <span class="o">*</span><span class="n">acc</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"data"</span><span class="p">,</span> <span class="s2">"optimization"</span><span class="p">,</span> <span class="s2">"ops"</span><span class="p">,</span> <span class="s2">"type"</span><span class="p">,</span> <span class="s2">"size"</span><span class="p">,</span> <span class="s2">"status"</span><span class="p">,</span> <span class="s2">"accuracy"</span><span class="p">,</span><span class="s2">"mean_inference"</span><span class="p">,</span><span class="s2">"std_inference"</span><span class="p">])</span>
<span class="n">result</span><span class="o">.</span><span class="n">to_pickle</span><span class="p">(</span><span class="s2">"result.pkl"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">"result.pkl"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="nx">javascript</span>
<span class="nx">require</span><span class="p">.</span><span class="nx">config</span><span class="p">({</span>
    <span class="nx">paths</span><span class="o">:</span> <span class="p">{</span>
        <span class="nx">DT</span><span class="o">:</span> <span class="s1">'//cdn.datatables.net/1.10.19/js/jquery.dataTables.min'</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">});</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>





<div id="e33644e3-4b31-46e6-85bc-de7394c5d822"></div>
<div class="output_subarea output_javascript ">
<script type="text/javascript">
var element = $('#e33644e3-4b31-46e6-85bc-de7394c5d822');
require.config({
    paths: {
        DT: '//cdn.datatables.net/1.10.19/js/jquery.dataTables.min',
    }
});
</script>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Raw-results">Raw results<a class="anchor-link" href="#Raw-results">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">HTML</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">to_html</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[0]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<table border="1" class="dataframe">
<thead><tr style="text-align: right;">
<th></th>
      <th>data</th>
      <th>optimization</th>
      <th>ops</th>
      <th>type</th>
      <th>size</th>
      <th>status</th>
      <th>accuracy</th>
      <th>mean_inference</th>
      <th>std_inference</th>
    </tr></thead>
<tbody>
<tr>
<th>0</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>float</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>1</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>float16</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>2</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>3</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>int32</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>4</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>int64</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>5</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001737</td>
      <td>0.001835</td>
    </tr>
<tr>
<th>6</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>quantized_uint8</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>7</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>string</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>8</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>9</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000083</td>
    </tr>
<tr>
<th>10</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001719</td>
      <td>0.000059</td>
    </tr>
<tr>
<th>11</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000026</td>
    </tr>
<tr>
<th>12</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>13</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000060</td>
    </tr>
<tr>
<th>14</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001719</td>
      <td>0.000059</td>
    </tr>
<tr>
<th>15</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001718</td>
      <td>0.000060</td>
    </tr>
<tr>
<th>16</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001722</td>
      <td>0.000087</td>
    </tr>
<tr>
<th>17</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001718</td>
      <td>0.000059</td>
    </tr>
<tr>
<th>18</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>19</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001744</td>
      <td>0.002122</td>
    </tr>
<tr>
<th>20</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000054</td>
    </tr>
<tr>
<th>21</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000021</td>
    </tr>
<tr>
<th>22</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>23</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001726</td>
      <td>0.000068</td>
    </tr>
<tr>
<th>24</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000058</td>
    </tr>
<tr>
<th>25</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000070</td>
    </tr>
<tr>
<th>26</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001727</td>
      <td>0.000104</td>
    </tr>
<tr>
<th>27</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001713</td>
      <td>0.000051</td>
    </tr>
<tr>
<th>28</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>29</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001715</td>
      <td>0.000049</td>
    </tr>
<tr>
<th>30</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>float</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>31</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>float16</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>32</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>33</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>int32</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>34</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>int64</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>35</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000119</td>
    </tr>
<tr>
<th>36</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>quantized_uint8</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>37</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>string</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>38</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>39</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000070</td>
    </tr>
<tr>
<th>40</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000072</td>
    </tr>
<tr>
<th>41</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000024</td>
    </tr>
<tr>
<th>42</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>43</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001719</td>
      <td>0.000080</td>
    </tr>
<tr>
<th>44</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001718</td>
      <td>0.000060</td>
    </tr>
<tr>
<th>45</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000063</td>
    </tr>
<tr>
<th>46</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000060</td>
    </tr>
<tr>
<th>47</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001727</td>
      <td>0.000079</td>
    </tr>
<tr>
<th>48</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>49</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001715</td>
      <td>0.000067</td>
    </tr>
<tr>
<th>50</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001714</td>
      <td>0.000049</td>
    </tr>
<tr>
<th>51</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000030</td>
    </tr>
<tr>
<th>52</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>53</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001725</td>
      <td>0.000072</td>
    </tr>
<tr>
<th>54</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000058</td>
    </tr>
<tr>
<th>55</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001739</td>
      <td>0.002140</td>
    </tr>
<tr>
<th>56</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001713</td>
      <td>0.000066</td>
    </tr>
<tr>
<th>57</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001709</td>
      <td>0.000040</td>
    </tr>
<tr>
<th>58</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>59</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001714</td>
      <td>0.000067</td>
    </tr>
<tr>
<th>60</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>float</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>61</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>float16</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>62</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>63</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>int32</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>64</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>int64</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>65</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001711</td>
      <td>0.000049</td>
    </tr>
<tr>
<th>66</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>quantized_uint8</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>67</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>string</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>68</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>69</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000065</td>
    </tr>
<tr>
<th>70</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000055</td>
    </tr>
<tr>
<th>71</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>72</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>73</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000069</td>
    </tr>
<tr>
<th>74</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000057</td>
    </tr>
<tr>
<th>75</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000059</td>
    </tr>
<tr>
<th>76</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000070</td>
    </tr>
<tr>
<th>77</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001743</td>
      <td>0.002344</td>
    </tr>
<tr>
<th>78</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>79</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000053</td>
    </tr>
<tr>
<th>80</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001720</td>
      <td>0.000098</td>
    </tr>
<tr>
<th>81</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000298</td>
      <td>0.000024</td>
    </tr>
<tr>
<th>82</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>83</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000052</td>
    </tr>
<tr>
<th>84</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001740</td>
      <td>0.002122</td>
    </tr>
<tr>
<th>85</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001719</td>
      <td>0.000070</td>
    </tr>
<tr>
<th>86</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001713</td>
      <td>0.000043</td>
    </tr>
<tr>
<th>87</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000061</td>
    </tr>
<tr>
<th>88</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>89</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000057</td>
    </tr>
<tr>
<th>90</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>float</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>91</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>float16</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>92</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>93</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>int32</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>94</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>int64</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>95</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000063</td>
    </tr>
<tr>
<th>96</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>quantized_uint8</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>97</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>string</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>98</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>99</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000071</td>
    </tr>
<tr>
<th>100</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>float</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000032</td>
    </tr>
<tr>
<th>101</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>float16</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000021</td>
    </tr>
<tr>
<th>102</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>103</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>int32</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>104</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>int64</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000026</td>
    </tr>
<tr>
<th>105</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000061</td>
    </tr>
<tr>
<th>106</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000023</td>
    </tr>
<tr>
<th>107</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>string</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000028</td>
    </tr>
<tr>
<th>108</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>109</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>none</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000023</td>
    </tr>
<tr>
<th>110</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>float</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000302</td>
      <td>0.000024</td>
    </tr>
<tr>
<th>111</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>float16</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>112</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>113</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>int32</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000034</td>
    </tr>
<tr>
<th>114</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>int64</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>115</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001720</td>
      <td>0.000062</td>
    </tr>
<tr>
<th>116</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>117</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>string</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000026</td>
    </tr>
<tr>
<th>118</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>119</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>none</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>120</th>
      <td>wo_data</td>
      <td>default</td>
      <td>int8</td>
      <td>float</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>121</th>
      <td>wo_data</td>
      <td>default</td>
      <td>int8</td>
      <td>float16</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>122</th>
      <td>wo_data</td>
      <td>default</td>
      <td>int8</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>123</th>
      <td>wo_data</td>
      <td>default</td>
      <td>int8</td>
      <td>int32</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>124</th>
      <td>wo_data</td>
      <td>default</td>
      <td>int8</td>
      <td>int64</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>125</th>
      <td>wo_data</td>
      <td>default</td>
      <td>int8</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>126</th>
      <td>wo_data</td>
      <td>default</td>
      <td>int8</td>
      <td>quantized_uint8</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>127</th>
      <td>wo_data</td>
      <td>default</td>
      <td>int8</td>
      <td>string</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>128</th>
      <td>wo_data</td>
      <td>default</td>
      <td>int8</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>129</th>
      <td>wo_data</td>
      <td>default</td>
      <td>int8</td>
      <td>none</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>130</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000203</td>
      <td>0.000023</td>
    </tr>
<tr>
<th>131</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000026</td>
    </tr>
<tr>
<th>132</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>133</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000193</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>134</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000190</td>
      <td>0.000020</td>
    </tr>
<tr>
<th>135</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>136</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000191</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>137</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000196</td>
      <td>0.000019</td>
    </tr>
<tr>
<th>138</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>139</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000191</td>
      <td>0.000016</td>
    </tr>
<tr>
<th>140</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000192</td>
      <td>0.000019</td>
    </tr>
<tr>
<th>141</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>142</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>143</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000194</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>144</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000188</td>
      <td>0.000016</td>
    </tr>
<tr>
<th>145</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>146</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000198</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>147</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000197</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>148</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>149</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000189</td>
      <td>0.000014</td>
    </tr>
<tr>
<th>150</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>float</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>151</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>float16</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>152</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>153</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>int32</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>154</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>int64</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>155</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>156</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>quantized_uint8</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>157</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>string</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>158</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>159</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>none</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>160</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000195</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>161</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000302</td>
      <td>0.000030</td>
    </tr>
<tr>
<th>162</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>163</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000197</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>164</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000213</td>
      <td>0.002201</td>
    </tr>
<tr>
<th>165</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>166</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000194</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>167</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000190</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>168</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>169</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000189</td>
      <td>0.000016</td>
    </tr>
<tr>
<th>170</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000188</td>
      <td>0.000014</td>
    </tr>
<tr>
<th>171</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000321</td>
      <td>0.002138</td>
    </tr>
<tr>
<th>172</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>173</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000196</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>174</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000191</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>175</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>176</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000195</td>
      <td>0.000024</td>
    </tr>
<tr>
<th>177</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000202</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>178</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>179</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000190</td>
      <td>0.000016</td>
    </tr>
<tr>
<th>180</th>
      <td>wo_data</td>
      <td>size</td>
      <td>int8</td>
      <td>float</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>181</th>
      <td>wo_data</td>
      <td>size</td>
      <td>int8</td>
      <td>float16</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>182</th>
      <td>wo_data</td>
      <td>size</td>
      <td>int8</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>183</th>
      <td>wo_data</td>
      <td>size</td>
      <td>int8</td>
      <td>int32</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>184</th>
      <td>wo_data</td>
      <td>size</td>
      <td>int8</td>
      <td>int64</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>185</th>
      <td>wo_data</td>
      <td>size</td>
      <td>int8</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>186</th>
      <td>wo_data</td>
      <td>size</td>
      <td>int8</td>
      <td>quantized_uint8</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>187</th>
      <td>wo_data</td>
      <td>size</td>
      <td>int8</td>
      <td>string</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>188</th>
      <td>wo_data</td>
      <td>size</td>
      <td>int8</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>189</th>
      <td>wo_data</td>
      <td>size</td>
      <td>int8</td>
      <td>none</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>190</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000192</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>191</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>192</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>193</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000203</td>
      <td>0.000021</td>
    </tr>
<tr>
<th>194</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000194</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>195</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>196</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000197</td>
      <td>0.000020</td>
    </tr>
<tr>
<th>197</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000194</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>198</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>199</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000200</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>200</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000212</td>
      <td>0.002256</td>
    </tr>
<tr>
<th>201</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000310</td>
      <td>0.000043</td>
    </tr>
<tr>
<th>202</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>203</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000192</td>
      <td>0.000016</td>
    </tr>
<tr>
<th>204</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000194</td>
      <td>0.000020</td>
    </tr>
<tr>
<th>205</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>206</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000191</td>
      <td>0.000015</td>
    </tr>
<tr>
<th>207</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000213</td>
      <td>0.002210</td>
    </tr>
<tr>
<th>208</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>209</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000195</td>
      <td>0.000019</td>
    </tr>
<tr>
<th>210</th>
      <td>wo_data</td>
      <td>none</td>
      <td>int8</td>
      <td>float</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>211</th>
      <td>wo_data</td>
      <td>none</td>
      <td>int8</td>
      <td>float16</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>212</th>
      <td>wo_data</td>
      <td>none</td>
      <td>int8</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>213</th>
      <td>wo_data</td>
      <td>none</td>
      <td>int8</td>
      <td>int32</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>214</th>
      <td>wo_data</td>
      <td>none</td>
      <td>int8</td>
      <td>int64</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>215</th>
      <td>wo_data</td>
      <td>none</td>
      <td>int8</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>216</th>
      <td>wo_data</td>
      <td>none</td>
      <td>int8</td>
      <td>quantized_uint8</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>217</th>
      <td>wo_data</td>
      <td>none</td>
      <td>int8</td>
      <td>string</td>
      <td>NaN</td>
      <td>TFLITE_BUILTINS_INT8 requires smallest supported type to be INT8.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>218</th>
      <td>wo_data</td>
      <td>none</td>
      <td>int8</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>219</th>
      <td>wo_data</td>
      <td>none</td>
      <td>int8</td>
      <td>none</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>220</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>float</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000023</td>
    </tr>
<tr>
<th>221</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>float16</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000322</td>
      <td>0.002276</td>
    </tr>
<tr>
<th>222</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>223</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>int32</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>224</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>int64</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000302</td>
      <td>0.000031</td>
    </tr>
<tr>
<th>225</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>226</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000021</td>
    </tr>
<tr>
<th>227</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>string</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>228</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>229</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>none</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000021</td>
    </tr>
<tr>
<th>230</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>float</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>231</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>float16</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000048</td>
    </tr>
<tr>
<th>232</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>graphviz_dot</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>233</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>int32</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000028</td>
    </tr>
<tr>
<th>234</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>int64</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000024</td>
    </tr>
<tr>
<th>235</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>int8</td>
      <td>NaN</td>
      <td>representative_dataset is required when specifying TFLITE_BUILTINS_INT8 or INT8 supported types.</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>236</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000023</td>
    </tr>
<tr>
<th>237</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>string</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>238</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>tflite</td>
      <td>NaN</td>
      <td>'int' object has no attribute 'size'</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
<tr>
<th>239</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>none</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000026</td>
    </tr>
</tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Finished-tf-lite-models">Finished tf lite models<a class="anchor-link" href="#Finished-tf-lite-models">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">HTML</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">to_html</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[0]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<table border="1" class="dataframe">
<thead><tr style="text-align: right;">
<th></th>
      <th>data</th>
      <th>optimization</th>
      <th>ops</th>
      <th>type</th>
      <th>size</th>
      <th>status</th>
      <th>accuracy</th>
      <th>mean_inference</th>
      <th>std_inference</th>
    </tr></thead>
<tbody>
<tr>
<th>5</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001737</td>
      <td>0.001835</td>
    </tr>
<tr>
<th>9</th>
      <td>with_data</td>
      <td>default</td>
      <td>int8</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000083</td>
    </tr>
<tr>
<th>10</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001719</td>
      <td>0.000059</td>
    </tr>
<tr>
<th>11</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000026</td>
    </tr>
<tr>
<th>13</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000060</td>
    </tr>
<tr>
<th>14</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001719</td>
      <td>0.000059</td>
    </tr>
<tr>
<th>15</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001718</td>
      <td>0.000060</td>
    </tr>
<tr>
<th>16</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001722</td>
      <td>0.000087</td>
    </tr>
<tr>
<th>17</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001718</td>
      <td>0.000059</td>
    </tr>
<tr>
<th>19</th>
      <td>with_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001744</td>
      <td>0.002122</td>
    </tr>
<tr>
<th>20</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000054</td>
    </tr>
<tr>
<th>21</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000021</td>
    </tr>
<tr>
<th>23</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001726</td>
      <td>0.000068</td>
    </tr>
<tr>
<th>24</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000058</td>
    </tr>
<tr>
<th>25</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000070</td>
    </tr>
<tr>
<th>26</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001727</td>
      <td>0.000104</td>
    </tr>
<tr>
<th>27</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001713</td>
      <td>0.000051</td>
    </tr>
<tr>
<th>29</th>
      <td>with_data</td>
      <td>default</td>
      <td>tf</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001715</td>
      <td>0.000049</td>
    </tr>
<tr>
<th>35</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000119</td>
    </tr>
<tr>
<th>39</th>
      <td>with_data</td>
      <td>latency</td>
      <td>int8</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000070</td>
    </tr>
<tr>
<th>40</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000072</td>
    </tr>
<tr>
<th>41</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000024</td>
    </tr>
<tr>
<th>43</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001719</td>
      <td>0.000080</td>
    </tr>
<tr>
<th>44</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001718</td>
      <td>0.000060</td>
    </tr>
<tr>
<th>45</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000063</td>
    </tr>
<tr>
<th>46</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000060</td>
    </tr>
<tr>
<th>47</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001727</td>
      <td>0.000079</td>
    </tr>
<tr>
<th>49</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001715</td>
      <td>0.000067</td>
    </tr>
<tr>
<th>50</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001714</td>
      <td>0.000049</td>
    </tr>
<tr>
<th>51</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000030</td>
    </tr>
<tr>
<th>53</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001725</td>
      <td>0.000072</td>
    </tr>
<tr>
<th>54</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000058</td>
    </tr>
<tr>
<th>55</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001739</td>
      <td>0.002140</td>
    </tr>
<tr>
<th>56</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001713</td>
      <td>0.000066</td>
    </tr>
<tr>
<th>57</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001709</td>
      <td>0.000040</td>
    </tr>
<tr>
<th>59</th>
      <td>with_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001714</td>
      <td>0.000067</td>
    </tr>
<tr>
<th>65</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001711</td>
      <td>0.000049</td>
    </tr>
<tr>
<th>69</th>
      <td>with_data</td>
      <td>size</td>
      <td>int8</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000065</td>
    </tr>
<tr>
<th>70</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000055</td>
    </tr>
<tr>
<th>71</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>73</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000069</td>
    </tr>
<tr>
<th>74</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000057</td>
    </tr>
<tr>
<th>75</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000059</td>
    </tr>
<tr>
<th>76</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000070</td>
    </tr>
<tr>
<th>77</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001743</td>
      <td>0.002344</td>
    </tr>
<tr>
<th>79</th>
      <td>with_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000053</td>
    </tr>
<tr>
<th>80</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>float</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001720</td>
      <td>0.000098</td>
    </tr>
<tr>
<th>81</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000298</td>
      <td>0.000024</td>
    </tr>
<tr>
<th>83</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>int32</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000052</td>
    </tr>
<tr>
<th>84</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>int64</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001740</td>
      <td>0.002122</td>
    </tr>
<tr>
<th>85</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001719</td>
      <td>0.000070</td>
    </tr>
<tr>
<th>86</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001713</td>
      <td>0.000043</td>
    </tr>
<tr>
<th>87</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>string</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000061</td>
    </tr>
<tr>
<th>89</th>
      <td>with_data</td>
      <td>size</td>
      <td>tf</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001716</td>
      <td>0.000057</td>
    </tr>
<tr>
<th>95</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000063</td>
    </tr>
<tr>
<th>99</th>
      <td>with_data</td>
      <td>none</td>
      <td>int8</td>
      <td>none</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001717</td>
      <td>0.000071</td>
    </tr>
<tr>
<th>100</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>float</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000032</td>
    </tr>
<tr>
<th>101</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>float16</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000021</td>
    </tr>
<tr>
<th>103</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>int32</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>104</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>int64</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000026</td>
    </tr>
<tr>
<th>105</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001721</td>
      <td>0.000061</td>
    </tr>
<tr>
<th>106</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000023</td>
    </tr>
<tr>
<th>107</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>string</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000028</td>
    </tr>
<tr>
<th>109</th>
      <td>with_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>none</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000023</td>
    </tr>
<tr>
<th>110</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>float</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000302</td>
      <td>0.000024</td>
    </tr>
<tr>
<th>111</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>float16</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>113</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>int32</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000303</td>
      <td>0.000034</td>
    </tr>
<tr>
<th>114</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>int64</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>115</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>int8</td>
      <td>60976.0</td>
      <td>success</td>
      <td>0.9869</td>
      <td>0.001720</td>
      <td>0.000062</td>
    </tr>
<tr>
<th>116</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>117</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>string</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000026</td>
    </tr>
<tr>
<th>119</th>
      <td>with_data</td>
      <td>none</td>
      <td>tf</td>
      <td>none</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>130</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000203</td>
      <td>0.000023</td>
    </tr>
<tr>
<th>131</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000026</td>
    </tr>
<tr>
<th>133</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000193</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>134</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000190</td>
      <td>0.000020</td>
    </tr>
<tr>
<th>136</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000191</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>137</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000196</td>
      <td>0.000019</td>
    </tr>
<tr>
<th>139</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tflite</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000191</td>
      <td>0.000016</td>
    </tr>
<tr>
<th>140</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000192</td>
      <td>0.000019</td>
    </tr>
<tr>
<th>141</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>143</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000194</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>144</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000188</td>
      <td>0.000016</td>
    </tr>
<tr>
<th>146</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000198</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>147</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000197</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>149</th>
      <td>wo_data</td>
      <td>default</td>
      <td>tf</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000189</td>
      <td>0.000014</td>
    </tr>
<tr>
<th>160</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000195</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>161</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000302</td>
      <td>0.000030</td>
    </tr>
<tr>
<th>163</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000197</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>164</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000213</td>
      <td>0.002201</td>
    </tr>
<tr>
<th>166</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000194</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>167</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000190</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>169</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tflite</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000189</td>
      <td>0.000016</td>
    </tr>
<tr>
<th>170</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000188</td>
      <td>0.000014</td>
    </tr>
<tr>
<th>171</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000321</td>
      <td>0.002138</td>
    </tr>
<tr>
<th>173</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000196</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>174</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000191</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>176</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000195</td>
      <td>0.000024</td>
    </tr>
<tr>
<th>177</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000202</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>179</th>
      <td>wo_data</td>
      <td>latency</td>
      <td>tf</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000190</td>
      <td>0.000016</td>
    </tr>
<tr>
<th>190</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000192</td>
      <td>0.000017</td>
    </tr>
<tr>
<th>191</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>193</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000203</td>
      <td>0.000021</td>
    </tr>
<tr>
<th>194</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000194</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>196</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000197</td>
      <td>0.000020</td>
    </tr>
<tr>
<th>197</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000194</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>199</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tflite</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000200</td>
      <td>0.000018</td>
    </tr>
<tr>
<th>200</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>float</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000212</td>
      <td>0.002256</td>
    </tr>
<tr>
<th>201</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>float16</td>
      <td>114928.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000310</td>
      <td>0.000043</td>
    </tr>
<tr>
<th>203</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>int32</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000192</td>
      <td>0.000016</td>
    </tr>
<tr>
<th>204</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>int64</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000194</td>
      <td>0.000020</td>
    </tr>
<tr>
<th>206</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000191</td>
      <td>0.000015</td>
    </tr>
<tr>
<th>207</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>string</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000213</td>
      <td>0.002210</td>
    </tr>
<tr>
<th>209</th>
      <td>wo_data</td>
      <td>size</td>
      <td>tf</td>
      <td>none</td>
      <td>59648.0</td>
      <td>success</td>
      <td>0.9864</td>
      <td>0.000195</td>
      <td>0.000019</td>
    </tr>
<tr>
<th>220</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>float</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000023</td>
    </tr>
<tr>
<th>221</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>float16</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000322</td>
      <td>0.002276</td>
    </tr>
<tr>
<th>223</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>int32</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>224</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>int64</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000302</td>
      <td>0.000031</td>
    </tr>
<tr>
<th>226</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>quantized_uint8</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000021</td>
    </tr>
<tr>
<th>227</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>string</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>229</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tflite</td>
      <td>none</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000021</td>
    </tr>
<tr>
<th>230</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>float</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000022</td>
    </tr>
<tr>
<th>231</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>float16</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000048</td>
    </tr>
<tr>
<th>233</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>int32</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000301</td>
      <td>0.000028</td>
    </tr>
<tr>
<th>234</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>int64</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000299</td>
      <td>0.000024</td>
    </tr>
<tr>
<th>236</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>quantized_uint8</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000023</td>
    </tr>
<tr>
<th>237</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>string</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000025</td>
    </tr>
<tr>
<th>239</th>
      <td>wo_data</td>
      <td>none</td>
      <td>tf</td>
      <td>none</td>
      <td>223952.0</td>
      <td>success</td>
      <td>0.9867</td>
      <td>0.000300</td>
      <td>0.000026</td>
    </tr>
</tbody>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="TF-Lite-Interpreter-result-details">TF Lite Interpreter result details<a class="anchor-link" href="#TF-Lite-Interpreter-result-details">¶</a>
</h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_gen</span> <span class="o">=</span> <span class="n">create_data</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Plain-TF-Lite-Convert">Plain TF Lite Convert<a class="anchor-link" href="#Plain-TF-Lite-Convert">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plain_tflite</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">get_res</span><span class="p">(</span><span class="s2">"tmp/wo_data-opt(none)-ops(tf)-type(float).tflite"</span><span class="p">,</span> <span class="n">data_gen</span><span class="p">)])</span>
<span class="n">mismatch</span><span class="p">,</span> <span class="n">diff</span> <span class="o">=</span> <span class="n">get_diff</span><span class="p">(</span><span class="n">plain_res</span><span class="p">,</span> <span class="n">plain_tflite</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"total mismatch=</span><span class="si">%d</span><span class="s2">"</span><span class="o">%</span><span class="k">mismatch</span>)
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYMAAAEVCAYAAAACW4lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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">
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">print_inpt</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
  <span class="n">intp</span> <span class="o">=</span> <span class="n">lite</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">intp</span><span class="o">.</span><span class="n">get_tensor_details</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\t</span><span class="s2">"</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">"</span><span class="si">%d</span><span class="s2">"</span><span class="o">%</span><span class="k">i</span>['index'], ("%s"%i['dtype']).split("'")[1].split('.')[1], i['name'], "%s"%i['shape'], "(%f,%f)"%i['quantization']]))
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">print_inpt</span><span class="p">(</span><span class="s2">"tmp/wo_data-opt(none)-ops(tf)-type(float).tflite"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0	float32	batch_normalization/FusedBatchNormV3	[ 1 26 26 16]	(0.000000,0.000000)
1	float32	batch_normalization/FusedBatchNormV3_add_param	[16]	(0.000000,0.000000)
2	float32	batch_normalization/FusedBatchNormV3_mul_0	[ 1 26 26 16]	(0.000000,0.000000)
3	float32	batch_normalization/FusedBatchNormV3_mul_0_param	[16]	(0.000000,0.000000)
4	float32	batch_normalization_1/FusedBatchNormV3	[ 1 11 11 16]	(0.000000,0.000000)
5	float32	batch_normalization_1/FusedBatchNormV3_add_param	[16]	(0.000000,0.000000)
6	float32	batch_normalization_1/FusedBatchNormV3_mul_0	[ 1 11 11 16]	(0.000000,0.000000)
7	float32	batch_normalization_1/FusedBatchNormV3_mul_0_param	[16]	(0.000000,0.000000)
8	float32	conv2d/Conv2D_bias	[16]	(0.000000,0.000000)
9	float32	conv2d/Relu	[ 1 26 26 16]	(0.000000,0.000000)
10	float32	conv2d/kernel	[ 1  3  3 16]	(0.000000,0.000000)
11	float32	conv2d_1/Conv2D_bias	[16]	(0.000000,0.000000)
12	float32	conv2d_1/Relu	[ 1 11 11 16]	(0.000000,0.000000)
13	float32	conv2d_1/kernel	[16  3  3 16]	(0.000000,0.000000)
14	float32	conv2d_input	[ 1 28 28  1]	(0.000000,0.000000)
15	float32	dense/MatMul_bias	[128]	(0.000000,0.000000)
16	float32	dense/Relu	[  1 128]	(0.000000,0.000000)
17	float32	dense/kernel/transpose	[128 400]	(0.000000,0.000000)
18	float32	dense_1/BiasAdd	[ 1 10]	(0.000000,0.000000)
19	float32	dense_1/MatMul_bias	[10]	(0.000000,0.000000)
20	float32	dense_1/Softmax	[ 1 10]	(0.000000,0.000000)
21	float32	dense_1/kernel/transpose	[ 10 128]	(0.000000,0.000000)
22	float32	max_pooling2d/MaxPool	[ 1 13 13 16]	(0.000000,0.000000)
23	float32	max_pooling2d_1/MaxPool	[ 1  5  5 16]	(0.000000,0.000000)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="TF-default-optimization">TF default optimization<a class="anchor-link" href="#TF-default-optimization">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plain_opt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">get_res</span><span class="p">(</span><span class="s2">"tmp/wo_data-opt(default)-ops(tflite)-type(float).tflite"</span><span class="p">,</span> <span class="n">data_gen</span><span class="p">)])</span>
<span class="n">mismatch</span><span class="p">,</span> <span class="n">diff</span> <span class="o">=</span> <span class="n">get_diff</span><span class="p">(</span><span class="n">plain_res</span><span class="p">,</span> <span class="n">plain_opt</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"total mismatch=</span><span class="si">%d</span><span class="s2">"</span><span class="o">%</span><span class="k">mismatch</span>)
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz%0AAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0%0AdHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAVgElEQVR4nO3dfbRddX3n8fdHwpMyQCARMQETSloL%0AHR1pivgwXS04PAmGWWMFdTBFOhlHHNuOVkBnBhbIVCmWFhUoJbHgYoCU6kB9KA0BlrRKNAgFARmu%0APEgiD4EAPjCgwe/8cX4XDpd7k9xzknPvJe/XWmedvX/7t3/7e25Ozuecvfc5O1WFJGnL9rKJLkCS%0ANPEMA0mSYSBJMgwkSRgGkiQMA0kShoFeYpL8TZJPbqKxzk/yPzbFWJtDkt9P8k8TXYdeGgwDDVSS%0A+5K8bXP135Sq6gNVdfogt7kpw2wc23xXkm8meSrJ9SOWzUjyz0keS/JEkm8lecsg69NgTJvoAiRN%0AuLXAXwCvBQ4cseynwPuBu4ECFgB/n+SVVbVuoFVqs/KTgQYmyReBPem8mPw0ycda+zuS3N7eeV6f%0A5Nc30P9vkzyU5Mkk30iy70Zu//fbu9yz27buSfLm1v5AkkeSLOzq/9y79PYO+SttvbVJbkjysrbs%0AviR/kuTWJD9LsjjJbkm+nuQnSa5JMr1r3FHrT7IIeC/wsfZ4/76175HkS0nWtHfonxvxuM5K8niS%0Ae5McNt5/l6q6pqqWAj8aZdnTVXVXVf0SCPAsMB3YZbzb0eRmGGhgqupY4IfAkVW1Q1WdmeRXgUuB%0APwJmAl+j8+K/zWj921BfB+YBrwS+C1wyjjLeCNwK7Ar8b+Ay4LeAvYH/CHwuyQ6jrPcRYFWrcTfg%0A43TeKQ/7D8C/A34VOLLV+PHW/2XAh7v6jlp/VV3Qps9sj/fIJFsBXwHuB+YAs1rN3Y/nLmAGcCaw%0AOEkAkpzbwmu0263j+JvR+j8NXAVcWFWPjGd9TX6GgSba0cBXq2pZVf0COAvYHnjzWCtU1ZKq+klV%0APQOcCrw+yU4bub17q+oLVfUscDmwB3BaVT1TVf8I/JxOMIz0C2B34DVV9YuquqFe+MNen62qh6tq%0ANXADsKKqbq6qp4EvA2/osf79gVcDf1JVP2vv1LsPGt9fVX/dHs9Frcbd2nY+WFU7j3F73Ub+vYZr%0Afh2wI/AewIPWL0GGgSbaq+m86wWg7Y54gM474BdJslWSTyX5QZIfA/e1RTM2cnsPd03/v7bNkW2j%0AfTL4M2AI+Me2e+mkDYw76pg91L8HnRf8sfbPPzQ8UVVPtcnR6u9bC6JLgZOSvH5zbEMTxzDQoI38%0AmdwfAa8Znmm7OPYAVo/R/z10DmK+DdiJzq4T6OzP3mzaO/mPVNVewDuA/5bkoB6G2lD9Ix/vA8Ce%0AScZ9skc7NfanY9xu76H2YVsDe/WxviYhw0CD9jAvfCFZCrw9yUFJtqazb/4Z4Jtj9P9XbfljwMuB%0A/7XZKwaSHJFk7xZWT9I5kPrLHobaUP0jH++3gQeBTyV5RZLtNvbUznZq7A5j3J476N4+rWxH5+zC%0Al7VtbN2WHZDkrUm2SbJ9khPp7IZa0cNj1yRmGGjQ/hT47+0g5ker6i46B24/CzxK5+DrkVX189H6%0AAxfT2a20GrgDuHFAdc8DrqFzquW3gHOr6roextlQ/YuBfdrj/T/tWMCRdI5j/JDOQeyje3sIYzqW%0Azq6s84B/26b/ui3bFvg8nfBaDRwOvL2qXnTmkaa2eHEbSZKfDCRJhoEkyTCQJGEYSJKYwj9UN2PG%0AjJozZ85ElyFJU8ZNN930aFXNHG3ZlA2DOXPmsHLlyokuQ5KmjCT3j7XM3USSJMNAkmQYSJIwDCRJ%0AGAaSJAwDSRIbEQZJlrRrw36vq22XJMuS3N3up7f2JDknyVC7Hux+XessbP3vHnGd2d9Mcltb55zh%0AS/ZJkgZnYz4Z/A1w6Ii2k4DlVTUPWN7mAQ6j81O/84BFdH4SlyS7AKfQuV7r/sApXRcIPw/4T13r%0AjdyWJGkz22AYVNU3gLUjmhfQud4q7f6orvaLq+NGYOckuwOHAMuqam1VPQ4sAw5ty3asqhvb9WQv%0A7hpLkjQgvX4DebeqerBNP0S7ADed69Y+0NVvVWtbX/uqUdpHlWQRnU8c7Lnnnj2Wri3NnJO++tz0%0Afdu9B4B/Pbfz/Fn6p89fWvjXv3/ni9ZdddINAFy43fLn2k499VQAXnXdLc+1PfS7/2bTFSxNgL4P%0AILd39AO5Qk5VXVBV86tq/syZo/68hiSpB72GwcNtFw/t/pHWvprOxcyHzW5t62ufPUq7JGmAeg2D%0Aq4DhM4IWAld2tb+vnVV0APBk2510NXBwkuntwPHBwNVt2Y/bRbcDvK9rLEnSgGzwmEGSS4HfAWYk%0AWUXnrKBPAUuTHE/n4t7vat2/RueC2UPAU8BxAFW1NsnpwHdav9Oqavig9AfpnLG0PfD1dpMkDdAG%0Aw6Cq3j3GooNG6VvACWOMswRYMkr7SuA3NlSHJGnz8RvIkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEk%0ACcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEr1fA1l6yfn8B64F4ITzD1xvv+XX/kpnIn+3uUuS%0ABsYwkEb4zNFHPDd99NwTJ7ASaXDcTSRJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwD%0ASRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSfQZBkn+OMntSb6X5NIk2yWZm2RFkqEklyfZpvXdts0P%0AteVzusY5ubXfleSQ/h6SJGm8eg6DJLOADwPzq+o3gK2AY4BPA2dX1d7A48DxbZXjgcdb+9mtH0n2%0AaevtCxwKnJtkq17rkiSNX7+7iaYB2yeZBrwceBA4ELiiLb8IOKpNL2jztOUHJUlrv6yqnqmqe4Eh%0AYP8+65IkjUPPYVBVq4GzgB/SCYEngZuAJ6pqXeu2CpjVpmcBD7R117X+u3a3j7LOCyRZlGRlkpVr%0A1qzptXRJ0gj97CaaTudd/Vzg1cAr6Ozm2Wyq6oKqml9V82fOnLk5NyVJW5R+dhO9Dbi3qtZU1S+A%0ALwFvAXZuu40AZgOr2/RqYA+Atnwn4LHu9lHWkSQNQD9h8EPggCQvb/v+DwLuAK4D3tn6LASubNNX%0AtXna8murqlr7Me1so7nAPODbfdQlSRqnaRvuMrqqWpHkCuC7wDrgZuAC4KvAZUk+2doWt1UWA19M%0AMgSspXMGEVV1e5KldIJkHXBCVT3ba12SpPHrOQwAquoU4JQRzfcwytlAVfU08HtjjHMGcEY/tUiS%0Aeuc3kCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQM%0AA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJ%0AGAaSJAwDSRKGgSSJPsMgyc5Jrkjy/SR3JnlTkl2SLEtyd7uf3vomyTlJhpLcmmS/rnEWtv53J1nY%0A74OSJI1Pv58M/hL4h6p6LfB64E7gJGB5Vc0Dlrd5gMOAee22CDgPIMkuwCnAG4H9gVOGA0SSNBg9%0Ah0GSnYDfBhYDVNXPq+oJYAFwUet2EXBUm14AXFwdNwI7J9kdOARYVlVrq+pxYBlwaK91SZLGr59P%0ABnOBNcAXktyc5MIkrwB2q6oHW5+HgN3a9Czgga71V7W2sdolSQPSTxhMA/YDzquqNwA/4/ldQgBU%0AVQHVxzZeIMmiJCuTrFyzZs2mGlaStnj9hMEqYFVVrWjzV9AJh4fb7h/a/SNt+Wpgj671Z7e2sdpf%0ApKouqKr5VTV/5syZfZQuSerWcxhU1UPAA0l+rTUdBNwBXAUMnxG0ELiyTV8FvK+dVXQA8GTbnXQ1%0AcHCS6e3A8cGtTZI0INP6XP+/Apck2Qa4BziOTsAsTXI8cD/wrtb3a8DhwBDwVOtLVa1Ncjrwndbv%0AtKpa22ddkqRx6CsMquoWYP4oiw4apW8BJ4wxzhJgST+1SJJ65zeQJUmGgSTJMJAkYRhIkjAMJEkY%0ABpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiS%0AMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJLEJgiDJFsl%0AuTnJV9r83CQrkgwluTzJNq192zY/1JbP6Rrj5NZ+V5JD+q1JkjQ+m+KTwR8Cd3bNfxo4u6r2Bh4H%0Ajm/txwOPt/azWz+S7AMcA+wLHAqcm2SrTVCXJGkj9RUGSWYDbwcubPMBDgSuaF0uAo5q0wvaPG35%0AQa3/AuCyqnqmqu4FhoD9+6lLkjQ+/X4y+AvgY8Av2/yuwBNVta7NrwJmtelZwAMAbfmTrf9z7aOs%0A8wJJFiVZmWTlmjVr+ixdkjSs5zBIcgTwSFXdtAnrWa+quqCq5lfV/JkzZw5qs5L0kjetj3XfArwj%0AyeHAdsCOwF8COyeZ1t79zwZWt/6rgT2AVUmmATsBj3W1D+teR5I0AD1/Mqiqk6tqdlXNoXMA+Nqq%0Aei9wHfDO1m0hcGWbvqrN05ZfW1XV2o9pZxvNBeYB3+61LknS+PXzyWAsJwKXJfkkcDOwuLUvBr6Y%0AZAhYSydAqKrbkywF7gDWASdU1bOboS5J0hg2SRhU1fXA9W36HkY5G6iqngZ+b4z1zwDO2BS1SJLG%0Az28gS5IMA0mSYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgG%0AkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIw%0ADCRJGAaSJAwDSRJ9hEGSPZJcl+SOJLcn+cPWvkuSZUnubvfTW3uSnJNkKMmtSfbrGmth6393koX9%0APyxJ0nj088lgHfCRqtoHOAA4Ick+wEnA8qqaByxv8wCHAfPabRFwHnTCAzgFeCOwP3DKcIBIkgaj%0A5zCoqger6rtt+ifAncAsYAFwUet2EXBUm14AXFwdNwI7J9kdOARYVlVrq+pxYBlwaK91SZLGb5Mc%0AM0gyB3gDsALYraoebIseAnZr07OAB7pWW9XaxmofbTuLkqxMsnLNmjWbonRJEpsgDJLsAPwd8EdV%0A9ePuZVVVQPW7ja7xLqiq+VU1f+bMmZtqWEna4vUVBkm2phMEl1TVl1rzw233D+3+kda+Gtija/XZ%0ArW2sdknSgPRzNlGAxcCdVfXnXYuuAobPCFoIXNnV/r52VtEBwJNtd9LVwMFJprcDxwe3NknSgEzr%0AY923AMcCtyW5pbV9HPgUsDTJ8cD9wLvasq8BhwNDwFPAcQBVtTbJ6cB3Wr/TqmptH3VJksap5zCo%0Aqn8CMsbig0bpX8AJY4y1BFjSay2SpP74DWRJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQ%0AJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CadD5z9BF85ugjJroMbWEMA0lSX1c6e8n7/AeuBeCE8w+c%0A4EokbYmWX/srz00fdOAPNuu2/GQgSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kS%0AhoEkCcNAkoRhIEnCMJAkYRhIkjAMJElMojBIcmiSu5IMJTlpouuRpC3JpAiDJFsBnwcOA/YB3p1k%0An4mtSpK2HJMiDID9gaGquqeqfg5cBiyY4JokaYuRqproGkjyTuDQqvqDNn8s8Maq+tCIfouARW32%0A14C7Blroi80AHp3gGsZjqtUL1jwIU61esOZevaaqZo62YNqgK+lHVV0AXDDRdQxLsrKq5k90HRtr%0AqtUL1jwIU61esObNYbLsJloN7NE1P7u1SZIGYLKEwXeAeUnmJtkGOAa4aoJrkqQtxqTYTVRV65J8%0ACLga2ApYUlW3T3BZG2PS7LLaSFOtXrDmQZhq9YI1b3KT4gCyJGliTZbdRJKkCWQYSJIMA4AkuyRZ%0AluTudj99jH4LW5+7kyzsav/NJLe1n9I4J0nWN26SBUluTXJLkpVJ3joFan5vq/m2JN9M8vpJXu9r%0Ak3wryTNJPjrOWtf70yhJtk1yeVu+IsmcrmUnt/a7khyyoTHbSRMrWvvl7QSKcRtwzR9qbZVkxhSo%0A95LW/r0kS5JsPQVqXpzkX9r/uSuS7NBLzeNSVVv8DTgTOKlNnwR8epQ+uwD3tPvpbXp6W/Zt4AAg%0AwNeBw9Y3LrADzx+veR3w/SlQ85u71j0MWDHJ630l8FvAGcBHx1HnVsAPgL2AbYB/AfYZ0eeDwPlt%0A+hjg8ja9T+u/LTC3jbPV+sYElgLHtOnzgf/Sw3Nh0DW/AZgD3AfMmAL1Ht6eNwEunSJ/4x27xv1z%0A2nN8c942+wvtVLjR+Sbz7m16d+CuUfq8G/irrvm/am270/Vi3t1vI8d9E3DnFKt5OrB6KtQLnMr4%0AwuBNwNVd8ycDJ4/oczXwpjY9jc63SjOy73C/scZs6zwKTBtt25Ox5hFj3kdvYTAh9bb2PwbOmCo1%0At/XPA04cb83jvbmbqGO3qnqwTT8E7DZKn1nAA13zq1rbrDY9sn294yb590m+D3wVeP9UqLnL8XTe%0AnU+VesdjrBpG7VNV64AngV03UP9o7bsCT7QxxtrWZKt5U5iQetvuoWOBf5gKNSf5Ap3n9GuBz/ZQ%0A87hMiu8ZDEKSa4BXjbLoE90zVVVJNvn5tiPHraovA19O8tvA6cDbRq4z2WpuNf0unTB40XGOyViv%0A1OVc4BtVdcNEF7Ixquq4dH7R+bPA0cAXNuf2tpgwqKoXvdgOS/Jwkt2r6sEkuwOPjNJtNfA7XfOz%0Agetb++wR7cM/pbHBcavqG0n2SjKjqh4dsWxS1ZzkdcCFdPbXPzbKY5lU9fZoY34aZbjPqiTTgJ2A%0Axzaw7mjtjwE7J5nW3kn2+jMsg6x5Uxh4vUlOAWYC/3mq1AxQVc8muQz4GJs5DDbrPqipcgP+jBce%0AhDxzlD67APfS2V8+vU3v0paNPLh5+PrGBfbm+QPI+9F5AmSS17wnMAS8eSr8jbvGPJXxHTOYRufA%0A9VyeP6i374g+J/DCA4VL2/S+vPBA4T10DhKOOSbwt7zwAPIHe/jbDrTmrjHvo7djBoP+G/8B8E1g%0A+z5eIwZWM53n+N5t3QBnAWf1WvtGP8bNvYGpcKOzX285cDdwDc+/AM0HLuzq9346L4hDwHFd7fOB%0A79E5M+BzPP9CP9a4JwK3A7cA3wLeOgVqvhB4vNV8C7Byktf7Kjr7YH8MPNGmd9zIWg8H/m/b1ida%0A22nAO9r0dnRexIfohNReXet+oq13F+2Mp7HGbO17tTGG2pjb9vgcHmTNH25/z3XAj7r//SZpveta%0A2/Bz939O5r8xnVP+/xm4jc5z/pKNfe72c/PnKCRJnk0kSTIMJEkYBpIkDANJEoaBJAnDQJKEYSBJ%0AAv4/judAPiGs0t0AAAAASUVORK5CYII=">
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">print_inpt</span><span class="p">(</span><span class="s2">"tmp/wo_data-opt(default)-ops(tflite)-type(float).tflite"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0	float32	batch_normalization/FusedBatchNormV3	[ 1 26 26 16]	(0.000000,0.000000)
1	float32	batch_normalization/FusedBatchNormV3_add_param	[16]	(0.000000,0.000000)
2	float32	batch_normalization/FusedBatchNormV3_mul_0	[ 1 26 26 16]	(0.000000,0.000000)
3	float32	batch_normalization/FusedBatchNormV3_mul_0_param	[16]	(0.000000,0.000000)
4	float32	batch_normalization_1/FusedBatchNormV3	[ 1 11 11 16]	(0.000000,0.000000)
5	float32	batch_normalization_1/FusedBatchNormV3_add_param	[16]	(0.000000,0.000000)
6	float32	batch_normalization_1/FusedBatchNormV3_mul_0	[ 1 11 11 16]	(0.000000,0.000000)
7	float32	batch_normalization_1/FusedBatchNormV3_mul_0_param	[16]	(0.000000,0.000000)
8	float32	conv2d/Conv2D_bias	[16]	(0.000000,0.000000)
9	float32	conv2d/Relu	[ 1 26 26 16]	(0.000000,0.000000)
10	float32	conv2d/kernel	[ 1  3  3 16]	(0.000000,0.000000)
11	float32	conv2d_1/Conv2D_bias	[16]	(0.000000,0.000000)
12	float32	conv2d_1/Relu	[ 1 11 11 16]	(0.000000,0.000000)
13	int8	conv2d_1/kernel	[16  3  3 16]	(0.002425,0.000000)
14	float32	conv2d_input	[ 1 28 28  1]	(0.000000,0.000000)
15	float32	dense/MatMul_bias	[128]	(0.000000,0.000000)
16	float32	dense/Relu	[  1 128]	(0.000000,0.000000)
17	int8	dense/kernel/transpose	[128 400]	(0.002713,0.000000)
18	float32	dense_1/BiasAdd	[ 1 10]	(0.000000,0.000000)
19	float32	dense_1/MatMul_bias	[10]	(0.000000,0.000000)
20	float32	dense_1/Softmax	[ 1 10]	(0.000000,0.000000)
21	int8	dense_1/kernel/transpose	[ 10 128]	(0.003590,0.000000)
22	float32	max_pooling2d/MaxPool	[ 1 13 13 16]	(0.000000,0.000000)
23	float32	max_pooling2d_1/MaxPool	[ 1  5  5 16]	(0.000000,0.000000)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="TF-with-representative-data">TF with representative data<a class="anchor-link" href="#TF-with-representative-data">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data_opt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">get_res</span><span class="p">(</span><span class="s2">"tmp/with_data-opt(default)-ops(tflite)-type(float).tflite"</span><span class="p">,</span> <span class="n">data_gen</span><span class="p">)])</span>
<span class="n">mismatch</span><span class="p">,</span> <span class="n">diff</span> <span class="o">=</span> <span class="n">get_diff</span><span class="p">(</span><span class="n">plain_res</span><span class="p">,</span> <span class="n">data_opt</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"total mismatch=</span><span class="si">%d</span><span class="s2">"</span><span class="o">%</span><span class="k">mismatch</span>)
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYsAAAEICAYAAACuxNj9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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">
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">print_inpt</span><span class="p">(</span><span class="s2">"tmp/with_data-opt(default)-ops(tflite)-type(float).tflite"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0	int8	batch_normalization/FusedBatchNormV3	[ 1 26 26 16]	(0.043397,-107.000000)
1	int8	batch_normalization/FusedBatchNormV3_add_param	[16]	(0.007060,0.000000)
2	int8	batch_normalization/FusedBatchNormV3_mul_0	[ 1 26 26 16]	(0.041571,-128.000000)
3	int8	batch_normalization/FusedBatchNormV3_mul_0_param	[16]	(0.239892,0.000000)
4	int8	batch_normalization_1/FusedBatchNormV3	[ 1 11 11 16]	(0.078118,-119.000000)
5	int8	batch_normalization_1/FusedBatchNormV3_add_param	[16]	(0.005670,0.000000)
6	int8	batch_normalization_1/FusedBatchNormV3_mul_0	[ 1 11 11 16]	(0.077301,-128.000000)
7	int8	batch_normalization_1/FusedBatchNormV3_mul_0_param	[16]	(0.021564,0.000000)
8	int32	conv2d/Conv2D_bias	[16]	(0.000000,0.000000)
9	int8	conv2d/Relu	[ 1 26 26 16]	(0.002887,-128.000000)
10	int8	conv2d/kernel	[ 1  3  3 16]	(0.000000,0.000000)
11	int32	conv2d_1/Conv2D_bias	[16]	(0.000000,0.000000)
12	int8	conv2d_1/Relu	[ 1 11 11 16]	(0.039788,-128.000000)
13	int8	conv2d_1/kernel	[16  3  3 16]	(0.000000,0.000000)
14	int8	conv2d_input_int8	[ 1 28 28  1]	(0.003922,-128.000000)
15	int32	dense/MatMul_bias	[128]	(0.000212,0.000000)
16	int8	dense/Relu	[  1 128]	(0.092764,-128.000000)
17	int8	dense/kernel/transpose	[128 400]	(0.002713,0.000000)
18	int8	dense_1/BiasAdd	[ 1 10]	(0.281922,-28.000000)
19	int32	dense_1/MatMul_bias	[10]	(0.000333,0.000000)
20	int8	dense_1/Softmax_int8	[ 1 10]	(0.003906,-128.000000)
21	int8	dense_1/kernel/transpose	[ 10 128]	(0.003590,0.000000)
22	int8	max_pooling2d/MaxPool	[ 1 13 13 16]	(0.043397,-107.000000)
23	int8	max_pooling2d_1/MaxPool	[ 1  5  5 16]	(0.078118,-119.000000)
24	float32	conv2d_input	[ 1 28 28  1]	(0.000000,0.000000)
25	float32	dense_1/Softmax	[ 1 10]	(0.000000,0.000000)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Other-quick-comparison">Other quick comparison<a class="anchor-link" href="#Other-quick-comparison">¶</a>
</h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">print_inpt</span><span class="p">(</span><span class="s2">"tmp/with_data-opt(default)-ops(int8)-type(int8).tflite"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0	int8	batch_normalization/FusedBatchNormV3	[ 1 26 26 16]	(0.043397,-107.000000)
1	int8	batch_normalization/FusedBatchNormV3_add_param	[16]	(0.007060,0.000000)
2	int8	batch_normalization/FusedBatchNormV3_mul_0	[ 1 26 26 16]	(0.041571,-128.000000)
3	int8	batch_normalization/FusedBatchNormV3_mul_0_param	[16]	(0.239892,0.000000)
4	int8	batch_normalization_1/FusedBatchNormV3	[ 1 11 11 16]	(0.078118,-119.000000)
5	int8	batch_normalization_1/FusedBatchNormV3_add_param	[16]	(0.005670,0.000000)
6	int8	batch_normalization_1/FusedBatchNormV3_mul_0	[ 1 11 11 16]	(0.077301,-128.000000)
7	int8	batch_normalization_1/FusedBatchNormV3_mul_0_param	[16]	(0.021564,0.000000)
8	int32	conv2d/Conv2D_bias	[16]	(0.000000,0.000000)
9	int8	conv2d/Relu	[ 1 26 26 16]	(0.002887,-128.000000)
10	int8	conv2d/kernel	[ 1  3  3 16]	(0.000000,0.000000)
11	int32	conv2d_1/Conv2D_bias	[16]	(0.000000,0.000000)
12	int8	conv2d_1/Relu	[ 1 11 11 16]	(0.039788,-128.000000)
13	int8	conv2d_1/kernel	[16  3  3 16]	(0.000000,0.000000)
14	int8	conv2d_input_int8	[ 1 28 28  1]	(0.003922,-128.000000)
15	int32	dense/MatMul_bias	[128]	(0.000212,0.000000)
16	int8	dense/Relu	[  1 128]	(0.092764,-128.000000)
17	int8	dense/kernel/transpose	[128 400]	(0.002713,0.000000)
18	int8	dense_1/BiasAdd	[ 1 10]	(0.281922,-28.000000)
19	int32	dense_1/MatMul_bias	[10]	(0.000333,0.000000)
20	int8	dense_1/Softmax_int8	[ 1 10]	(0.003906,-128.000000)
21	int8	dense_1/kernel/transpose	[ 10 128]	(0.003590,0.000000)
22	int8	max_pooling2d/MaxPool	[ 1 13 13 16]	(0.043397,-107.000000)
23	int8	max_pooling2d_1/MaxPool	[ 1  5  5 16]	(0.078118,-119.000000)
24	float32	conv2d_input	[ 1 28 28  1]	(0.000000,0.000000)
25	float32	dense_1/Softmax	[ 1 10]	(0.000000,0.000000)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">print_inpt</span><span class="p">(</span><span class="s2">"tmp/with_data-opt(size)-ops(tflite)-type(int8).tflite"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>0	int8	batch_normalization/FusedBatchNormV3	[ 1 26 26 16]	(0.043397,-107.000000)
1	int8	batch_normalization/FusedBatchNormV3_add_param	[16]	(0.007060,0.000000)
2	int8	batch_normalization/FusedBatchNormV3_mul_0	[ 1 26 26 16]	(0.041571,-128.000000)
3	int8	batch_normalization/FusedBatchNormV3_mul_0_param	[16]	(0.239892,0.000000)
4	int8	batch_normalization_1/FusedBatchNormV3	[ 1 11 11 16]	(0.078118,-119.000000)
5	int8	batch_normalization_1/FusedBatchNormV3_add_param	[16]	(0.005670,0.000000)
6	int8	batch_normalization_1/FusedBatchNormV3_mul_0	[ 1 11 11 16]	(0.077301,-128.000000)
7	int8	batch_normalization_1/FusedBatchNormV3_mul_0_param	[16]	(0.021564,0.000000)
8	int32	conv2d/Conv2D_bias	[16]	(0.000000,0.000000)
9	int8	conv2d/Relu	[ 1 26 26 16]	(0.002887,-128.000000)
10	int8	conv2d/kernel	[ 1  3  3 16]	(0.000000,0.000000)
11	int32	conv2d_1/Conv2D_bias	[16]	(0.000000,0.000000)
12	int8	conv2d_1/Relu	[ 1 11 11 16]	(0.039788,-128.000000)
13	int8	conv2d_1/kernel	[16  3  3 16]	(0.000000,0.000000)
14	int8	conv2d_input_int8	[ 1 28 28  1]	(0.003922,-128.000000)
15	int32	dense/MatMul_bias	[128]	(0.000212,0.000000)
16	int8	dense/Relu	[  1 128]	(0.092764,-128.000000)
17	int8	dense/kernel/transpose	[128 400]	(0.002713,0.000000)
18	int8	dense_1/BiasAdd	[ 1 10]	(0.281922,-28.000000)
19	int32	dense_1/MatMul_bias	[10]	(0.000333,0.000000)
20	int8	dense_1/Softmax_int8	[ 1 10]	(0.003906,-128.000000)
21	int8	dense_1/kernel/transpose	[ 10 128]	(0.003590,0.000000)
22	int8	max_pooling2d/MaxPool	[ 1 13 13 16]	(0.043397,-107.000000)
23	int8	max_pooling2d_1/MaxPool	[ 1  5  5 16]	(0.078118,-119.000000)
24	float32	conv2d_input	[ 1 28 28  1]	(0.000000,0.000000)
25	float32	dense_1/Softmax	[ 1 10]	(0.000000,0.000000)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Remarks">Remarks<a class="anchor-link" href="#Remarks">¶</a>
</h3>
<h4 id="Take-aways">Take-aways<a class="anchor-link" href="#Take-aways">¶</a>
</h4>
<p>Now, let's take another look of the workflow provided by TF.</p>
<p><img src="https://www.tensorflow.org/lite/performance/images/optimization.jpg" alt="Lite convert decision map"></p>
<ul>
<li>Optimization types are not fully implemented, see [here].(<a href="https://github.com/tensorflow/tensorflow/blob/570206441717511720fdae9ac58dac16cc1d348a/tensorflow/lite/python/lite.py#L96">https://github.com/tensorflow/tensorflow/blob/570206441717511720fdae9ac58dac16cc1d348a/tensorflow/lite/python/lite.py#L96</a>)</li>
<li>
<p>No data, no optimization, ops and types doesn't matter except crashing cases (e.g. int).  It will create a float32 tflite for runtime. This corresponds to <code>N</code> to <code>Optimzie model?</code>.</p>
<ul>
<li>Exception case 1: using int in types/ops</li>
<li>Exception case 2: with data, and set ops to int, (types is int or none).</li>
</ul>
</li>
<li>
<p>With optimization and types of <code>float16</code>, it will reduce to half size.</p>
</li>
<li>With optimization (and without float16), some weights are quantized to int8.</li>
<li>With data and optimization, weights are in int type. However int8 is not strictly enforced.</li>
<li>When ops is <code>int8</code>, data type needs to be <code>int8</code>.</li>
<li>int8 and uint8 are quite different.</li>
</ul>
<h4 id="Remaining-mysterious">Remaining mysterious<a class="anchor-link" href="#Remaining-mysterious">¶</a>
</h4>
<ul>
<li>What's the difference between <code>select</code> and <code>builtin</code>?</li>
<li>What's the <code>string</code> or <code>none</code> op type?</li>
</ul>
<h3 id="An-unexpected-problem">An unexpected problem<a class="anchor-link" href="#An-unexpected-problem">¶</a>
</h3>
<p>If you check the source code](<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/kernel_util.cc#L100">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/kernel_util.cc#L100</a>), it is under the <code>GetQuantizedConvolutionMultipler</code> function.  So there is some interesting conversion for the fully connected layer.  To save the trouble and focus on our original goal.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="p">[</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,)),</span>
     <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">),</span>
     <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>
<span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">"model2.h5"</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">data_gen</span><span class="p">():</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">yield</span> <span class="n">x</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">data_gen2</span><span class="p">():</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">data_gen</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">y</span><span class="p">:</span>
    <span class="k">yield</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>

<span class="k">if</span> <span class="n">ver1_flag</span><span class="p">:</span>
  <span class="n">conv</span> <span class="o">=</span> <span class="n">lite</span><span class="o">.</span><span class="n">TFLiteConverter</span><span class="o">.</span><span class="n">from_keras_model_file</span><span class="p">(</span><span class="s2">"model2.h5"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span> 
  <span class="n">conv</span> <span class="o">=</span> <span class="n">lite</span><span class="o">.</span><span class="n">TFLiteConverter</span><span class="o">.</span><span class="n">from_keras_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="n">conv</span><span class="o">.</span><span class="n">optimizations</span> <span class="o">=</span> <span class="p">[</span><span class="n">lite</span><span class="o">.</span><span class="n">Optimize</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">]</span>
<span class="n">conv</span><span class="o">.</span><span class="n">representative_dataset</span> <span class="o">=</span> <span class="n">data_gen2</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"problem.tflite"</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">conv</span><span class="o">.</span><span class="n">convert</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Froze 6 variables.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO:tensorflow:Froze 6 variables.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Converted 6 variables to const ops.
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>INFO:tensorflow:Converted 6 variables to const ops.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">intp</span> <span class="o">=</span> <span class="n">lite</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span><span class="s2">"problem.tflite"</span><span class="p">)</span>
<span class="n">intp</span><span class="o">.</span><span class="n">allocate_tensors</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-33-5338b2d27dd6&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> intp <span class="ansi-blue-fg">=</span> lite<span class="ansi-blue-fg">.</span>Interpreter<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"problem.tflite"</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>intp<span class="ansi-blue-fg">.</span>allocate_tensors<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter.py</span> in <span class="ansi-cyan-fg">allocate_tensors</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    242</span>   <span class="ansi-green-fg">def</span> allocate_tensors<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    243</span>     self<span class="ansi-blue-fg">.</span>_ensure_safe<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 244</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_interpreter<span class="ansi-blue-fg">.</span>AllocateTensors<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    245</span> 
<span class="ansi-green-intense-fg ansi-bold">    246</span>   <span class="ansi-green-fg">def</span> _safe_to_run<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py</span> in <span class="ansi-cyan-fg">AllocateTensors</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    104</span> 
<span class="ansi-green-intense-fg ansi-bold">    105</span>     <span class="ansi-green-fg">def</span> AllocateTensors<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 106</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> _tensorflow_wrap_interpreter_wrapper<span class="ansi-blue-fg">.</span>InterpreterWrapper_AllocateTensors<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    107</span> 
<span class="ansi-green-intense-fg ansi-bold">    108</span>     <span class="ansi-green-fg">def</span> Invoke<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">RuntimeError</span>: tensorflow/lite/kernels/kernel_util.cc:106 std::abs(input_product_scale - bias_scale) &lt;= 1e-6 * std::min(input_product_scale, bias_scale) was not true.Node number 2 (FULLY_CONNECTED) failed to prepare.
</pre>
</div>
</div>

</div>
</div>

</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/compression/" rel="tag">compression</a></li>
            <li><a class="tag p-category" href="../../categories/lite/" rel="tag">lite</a></li>
            <li><a class="tag p-category" href="../../categories/tensorflow/" rel="tag">tensorflow</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../imagenet-benchmark/" rel="prev" title="ImageNet Challenge Benchmark">Previous post</a>
            </li>
            <li class="next">
                <a href="../pocketflow-intro/" rel="next" title="PocketFlow unofficial guide">Next post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comments</h2>
        
        
<div id="fb-root"></div>
<script>
  window.fbAsyncInit = function() {
    // init the FB JS SDK
    FB.init({
      appId      : '321809675046639',
      status     : true,
      xfbml      : true
    });

  };

  // Load the SDK asynchronously
  (function(d, s, id){
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) {return;}
     js = d.createElement(s); js.id = id;
     js.src = "https://connect.facebook.net/en_US/all.js";
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script><div class="fb-comments" data-href="https://jiayiliu.github.com/posts/tensoflow-lite-convertor/" data-width="470"></div>


        </section><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha384-3lJUsx1TJHt7BA4udB5KPnDrlkO8T6J6v/op7ui0BbCjvZ9WqV4Xm6DTP6kQ/iBH" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></article><div id="fb-root"></div>
<script>
    // thank lxml for this
    $('.fb-comments-count').each(function(i, obj) {
        var url = obj.attributes['data-url'].value;
        // change here if you dislike the default way of displaying
        // this
        obj.innerHTML = '<fb:comments-count href="' + url + '"></fb:comments-count> comments';
    });

  window.fbAsyncInit = function() {
    // init the FB JS SDK
    FB.init({
      appId      : '321809675046639',
      status     : true,
      xfbml      : true
    });

  };

  // Load the SDK asynchronously
  (function(d, s, id){
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) {return;}
     js = d.createElement(s); js.id = id;
     js.src = "https://connect.facebook.net/en_US/all.js";
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script><!--End of body content--><footer id="footer">
            Contents © 2020         <a href="mailto:jiayi.uiuc@gmail.com">Jiayi (Jason) Liu</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-128364527-2"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-128364527-2');
</script>
</body>
</html>
