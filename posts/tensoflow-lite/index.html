<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
fb: http://ogp.me/ns/fb# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Tensorflow Lite, and reflection on Tensorflow Usability">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Reflection on Tensorflow Documentation by a short user journey | Lab of Random</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://jiayiliu.github.com/posts/tensoflow-lite/">
<meta property="fb:app_id" content="321809675046639">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script><!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Jiayi (Jason) Liu">
<link rel="prev" href="../tensoflow-profiling/" title="TensorFlow Profiling" type="text/html">
<meta property="og:site_name" content="Lab of Random">
<meta property="og:title" content="Reflection on Tensorflow Documentation by a short user journey">
<meta property="og:url" content="https://jiayiliu.github.com/posts/tensoflow-lite/">
<meta property="og:description" content="Tensorflow Lite, and reflection on Tensorflow Usability">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2019-05-25T17:13:01-08:00">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="https://jiayiliu.github.com/">

            <span id="blog-title">Lab of Random</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../../categories/" class="nav-link">Tags</a>
                </li>
<li class="nav-item">
<a href="../../rss.xml" class="nav-link">RSS feed</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right">
<li class="nav-item">
    <a href="index.ipynb" id="sourcelink" class="nav-link">Source</a>
    </li>


                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Reflection on Tensorflow Documentation by a short user journey</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    Jiayi (Jason) Liu
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2019-05-25T17:13:01-08:00" itemprop="datePublished" title="2019-05-25 17:13">2019-05-25 17:13</time></a>
            </p>
                <p class="commentline">
        
<span class="fb-comments-count" data-url="/posts/tensoflow-lite/">


            
        <p class="sourceline"><a href="index.ipynb" class="sourcelink">Source</a></p>

        </span></p>
</div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Reflection-on-Tensorflow-Documentation-by-a-short-user-journey">Reflection on Tensorflow Documentation by a short user journey<a class="anchor-link" href="#Reflection-on-Tensorflow-Documentation-by-a-short-user-journey">¶</a>
</h2>
<p>Tensorflow community keeps improving to address  <a href="http://nicodjimenez.github.io/2017/10/08/tensorflow.html">problems with Tensorflow</a>.</p>
<p>At the time of TF 2.0 release, I sitll found it is very painful to follow the TF documentation to get things done.  Here I write down some random notes during my short journey to use TF Lite for the quantization. Also I hope this tour can guide some other people to find an easier life when use TF.<!-- TEASER_END --></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">tf</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[1]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>'1.13.1'</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Honeymoon">Honeymoon<a class="anchor-link" href="#Honeymoon">¶</a>
</h3>
<p>The first glance of the TF Lite <a href="https://www.tensorflow.org/lite/convert/python_api">documentation</a> delights me by its well-organized structure and detailed documentation.</p>
<p>I followed the tutorial on the model conversion without worrying about <a href="https://www.reddit.com/r/MachineLearning/comments/6nupas/p_tensorflow_whats_the_best_way_to_saverestore/">the different ways of saving a TF model</a>.  And quickly, I got what I want - save a quantized model:</p>
<div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"img"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="n">const</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">])</span>
  <span class="n">val</span> <span class="o">=</span> <span class="n">img</span> <span class="o">+</span> <span class="n">const</span>
  <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fake_quant_with_min_max_args</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"output"</span><span class="p">)</span>

  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">converter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">TFLiteConverter</span><span class="o">.</span><span class="n">from_session</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="p">[</span><span class="n">img</span><span class="p">],</span> <span class="p">[</span><span class="n">out</span><span class="p">])</span>
    <span class="n">converter</span><span class="o">.</span><span class="n">inference_type</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="n">QUANTIZED_UINT8</span>
    <span class="n">input_arrays</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">get_input_arrays</span><span class="p">()</span>
    <span class="n">converter</span><span class="o">.</span><span class="n">quantized_input_stats</span> <span class="o">=</span> <span class="p">{</span><span class="n">input_arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span> <span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)}</span>  <span class="c1"># mean, std_dev</span>
    <span class="n">tflite_model</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">convert</span><span class="p">()</span>
    <span class="nb">open</span><span class="p">(</span><span class="s2">"converted_model.tflite"</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">tflite_model</span><span class="p">)</span>
</pre></div>
<p>Now, the pain starts - I could not find a solution to restore the quantized model to produce the right prediction!</p>
<p>And during my exploration on solving the challenge (yes, it is a challenge given the many misleading and confusing messages in the official documentation), I even start wondering whether TF community welcome users or it is just a propaganda tool for Google and no true intention for sharing.</p>
<p>Now let me show you my user journey towards the evil side of TF.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="A-simplified-model,-but-wait-...">A simplified model, but wait ...<a class="anchor-link" href="#A-simplified-model,-but-wait-...">¶</a>
</h3>
<p>OK, the first step, let me use a simpler model as follows,  a vector with a dimension of $1\times3$ adds to a constant vector $[1,2,3]$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"img"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="n">const</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
  <span class="n">val</span> <span class="o">=</span> <span class="n">img</span> <span class="o">+</span> <span class="n">const</span>
  <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">fake_quant_with_min_max_args</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">"output"</span><span class="p">)</span>
  
  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="p">{</span><span class="n">img</span><span class="p">:[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]]})</span>
<span class="n">v</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[2]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[1., 1., 1.]], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>OK, a quick glance hints the problem of the <code>fake_quant_with_min_max_args()</code>. Why using it in the origin code esp. the constants are all larger than 1?
Further digging into the documentation, I found there are 6 different functions all start with <code>fake_quant_with_min_max</code>.  If you are interested in understanding how to use them properly, follow the <a href="https://www.tensorflow.org/api_docs/python/tf/quantization/quantize">official documentation</a> or check the <a href="https://stackoverflow.com/questions/50524897/what-are-the-differences-between-tf-fake-quant-with-min-max-args-and-tf-fake-qua">stack-overflow explanation</a>.</p>
<p>I will skip it for now, as my goal is to recover the quantized model first.  And a quantized output with 0 and 1 clearly increases my difficulty to debug (or reduce the chance to find a bug).</p>
<p>For now, I replace it with an identity function and label the output name correspondingly.  And because that, I add <code>default_ranges_stats</code> in below to quantify the range of the internal values, (see <a href="https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/lite/python/lite.py">reference</a>).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"img"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="n">const</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
  <span class="n">val</span> <span class="o">=</span> <span class="n">img</span> <span class="o">+</span> <span class="n">const</span>
  <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'output'</span><span class="p">)</span> <span class="c1"># tf.fake_quant_with_min_max_args(val, min=0., max=1., name="output")</span>

  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">converter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">TFLiteConverter</span><span class="o">.</span><span class="n">from_session</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="p">[</span><span class="n">img</span><span class="p">],</span> <span class="p">[</span><span class="n">out</span><span class="p">])</span>
    <span class="n">converter</span><span class="o">.</span><span class="n">inference_type</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="n">QUANTIZED_UINT8</span>
    <span class="n">input_arrays</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">get_input_arrays</span><span class="p">()</span>
    <span class="n">converter</span><span class="o">.</span><span class="n">quantized_input_stats</span> <span class="o">=</span> <span class="p">{</span><span class="n">input_arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)}</span>  <span class="c1"># mean, std_dev</span>
    <span class="n">converter</span><span class="o">.</span><span class="n">default_ranges_stats</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">tflite_model</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">convert</span><span class="p">()</span>
    <span class="nb">open</span><span class="p">(</span><span class="s2">"example1.tflite"</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">tflite_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Originally, I searched for how to restore the model in Python under the <a href="https://www.tensorflow.org/lite/guide/inference">Inference</a>, but the reality is that it is only available under the <a href="https://www.tensorflow.org/lite/convert/python_api#using_the_interpreter_from_model_data_">Python API section</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">itp_full</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">"example1.tflite"</span><span class="p">)</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">allocate_tensors</span><span class="p">()</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">get_input_details</span><span class="p">(),</span> <span class="n">itp_full</span><span class="o">.</span><span class="n">get_output_details</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[4]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>([{'dtype': numpy.uint8,
   'index': 1,
   'name': 'img',
   'quantization': (1.0, 0),
   'shape': array([1, 3], dtype=int32)}],
 [{'dtype': numpy.uint8,
   'index': 2,
   'name': 'output',
   'quantization': (0.0117647061124444, 0),
   'shape': array([1, 3], dtype=int32)}])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">imgx</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">imgx</span><span class="p">)</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>
<span class="n">res</span><span class="o">=</span>  <span class="n">itp_full</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-5-138418d20125&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> imgx <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>itp_full<span class="ansi-blue-fg">.</span>set_tensor<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> imgx<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> itp_full<span class="ansi-blue-fg">.</span>invoke<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> res<span class="ansi-blue-fg">=</span>  itp_full<span class="ansi-blue-fg">.</span>get_tensor<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> res

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py</span> in <span class="ansi-cyan-fg">set_tensor</span><span class="ansi-blue-fg">(self, tensor_index, value)</span>
<span class="ansi-green-intense-fg ansi-bold">    173</span>       ValueError<span class="ansi-blue-fg">:</span> If the interpreter could <span class="ansi-green-fg">not</span> set the tensor<span class="ansi-blue-fg">.</span>
<span class="ansi-green-intense-fg ansi-bold">    174</span>     """
<span class="ansi-green-fg">--&gt; 175</span><span class="ansi-red-fg">     </span>self<span class="ansi-blue-fg">.</span>_interpreter<span class="ansi-blue-fg">.</span>SetTensor<span class="ansi-blue-fg">(</span>tensor_index<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    176</span> 
<span class="ansi-green-intense-fg ansi-bold">    177</span>   <span class="ansi-green-fg">def</span> resize_tensor_input<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input_index<span class="ansi-blue-fg">,</span> tensor_size<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py</span> in <span class="ansi-cyan-fg">SetTensor</span><span class="ansi-blue-fg">(self, i, value)</span>
<span class="ansi-green-intense-fg ansi-bold">    134</span> 
<span class="ansi-green-intense-fg ansi-bold">    135</span>     <span class="ansi-green-fg">def</span> SetTensor<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> i<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 136</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> _tensorflow_wrap_interpreter_wrapper<span class="ansi-blue-fg">.</span>InterpreterWrapper_SetTensor<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> i<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    137</span> 
<span class="ansi-green-intense-fg ansi-bold">    138</span>     <span class="ansi-green-fg">def</span> GetTensor<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> i<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">ValueError</span>: Cannot set tensor: Got tensor of type 4 but expected type 3 for input 1 </pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Comparing with the <code>input_details</code> in the previous block, it is might be clear to the reader already that the type is wrong.  But could TF kindly provide the type without any reference to find what's the hack the type 3 and 4 are???</p>
<p>A simple search guides me to this <a href="https://github.com/tensorflow/tensorflow/issues/22409">issue</a> which states the type " internal TFLite type casted from C++ type".  Fine, but still no clue on what are the...
And beneath that, <a href="https://github.com/tensorflow/tensorflow/issues/22409#issuecomment-432484940">Onetaken</a> provided a URL, which leads to 404..</p>
<p>Fine, I can spend an hour to dig into the details, but let's get back to the theme of this article -</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">imgx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span> <span class="c1"># cast to uint8</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">imgx</span><span class="p">)</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>
<span class="n">res</span><span class="o">=</span>  <span class="n">itp_full</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-6-11989c7451e0&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> imgx <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>array<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>astype<span class="ansi-blue-fg">(</span>np<span class="ansi-blue-fg">.</span>uint8<span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># cast to uint8</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span> itp_full<span class="ansi-blue-fg">.</span>set_tensor<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> imgx<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg"> </span>itp_full<span class="ansi-blue-fg">.</span>invoke<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> res<span class="ansi-blue-fg">=</span>  itp_full<span class="ansi-blue-fg">.</span>get_tensor<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> res

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py</span> in <span class="ansi-cyan-fg">invoke</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    274</span>       ValueError<span class="ansi-blue-fg">:</span> When the underlying interpreter fails <span class="ansi-green-fg">raise</span> ValueError<span class="ansi-blue-fg">.</span>
<span class="ansi-green-intense-fg ansi-bold">    275</span>     """
<span class="ansi-green-fg">--&gt; 276</span><span class="ansi-red-fg">     </span>self<span class="ansi-blue-fg">.</span>_ensure_safe<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    277</span>     self<span class="ansi-blue-fg">.</span>_interpreter<span class="ansi-blue-fg">.</span>Invoke<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    278</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py</span> in <span class="ansi-cyan-fg">_ensure_safe</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">     99</span>       <span class="ansi-green-fg">in</span> the interpreter <span class="ansi-green-fg">in</span> the form of a numpy array <span class="ansi-green-fg">or</span> slice<span class="ansi-blue-fg">.</span> Be sure to
<span class="ansi-green-intense-fg ansi-bold">    100</span>       only hold the function returned <span class="ansi-green-fg">from</span> tensor<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">if</span> you are using raw
<span class="ansi-green-fg">--&gt; 101</span><span class="ansi-red-fg">       data access.""")
</span><span class="ansi-green-intense-fg ansi-bold">    102</span> 
<span class="ansi-green-intense-fg ansi-bold">    103</span>   <span class="ansi-green-fg">def</span> _get_tensor_details<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> tensor_index<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">RuntimeError</span>: There is at least 1 reference to internal data
      in the interpreter in the form of a numpy array or slice. Be sure to
      only hold the function returned from tensor() if you are using raw
      data access.</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>What's the problem??   It follows the <a href="https://www.tensorflow.org/lite/convert/python_api#using_the_interpreter_from_a_model_file_">official documentation</a>  Anyway, found a solution on <a href="https://stackoverflow.com/questions/54006031/tf-lite-model-test-fails-with-run-time-error">Stack Overflow</a></p>
<p>Again, could TF documentation be more specific on the expected type of <code>set_tensor()</code>?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">imgx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]],</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span> <span class="c1"># cast to uint8</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">imgx</span><span class="p">)</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>
<span class="n">res</span><span class="o">=</span>  <span class="n">itp_full</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-7-da5825085942&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> imgx <span class="ansi-blue-fg">=</span> tf<span class="ansi-blue-fg">.</span>convert_to_tensor<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> np<span class="ansi-blue-fg">.</span>uint8<span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># cast to uint8</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>itp_full<span class="ansi-blue-fg">.</span>set_tensor<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> imgx<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> itp_full<span class="ansi-blue-fg">.</span>invoke<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> res<span class="ansi-blue-fg">=</span>  itp_full<span class="ansi-blue-fg">.</span>get_tensor<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> res

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py</span> in <span class="ansi-cyan-fg">set_tensor</span><span class="ansi-blue-fg">(self, tensor_index, value)</span>
<span class="ansi-green-intense-fg ansi-bold">    173</span>       ValueError<span class="ansi-blue-fg">:</span> If the interpreter could <span class="ansi-green-fg">not</span> set the tensor<span class="ansi-blue-fg">.</span>
<span class="ansi-green-intense-fg ansi-bold">    174</span>     """
<span class="ansi-green-fg">--&gt; 175</span><span class="ansi-red-fg">     </span>self<span class="ansi-blue-fg">.</span>_interpreter<span class="ansi-blue-fg">.</span>SetTensor<span class="ansi-blue-fg">(</span>tensor_index<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    176</span> 
<span class="ansi-green-intense-fg ansi-bold">    177</span>   <span class="ansi-green-fg">def</span> resize_tensor_input<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input_index<span class="ansi-blue-fg">,</span> tensor_size<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py</span> in <span class="ansi-cyan-fg">SetTensor</span><span class="ansi-blue-fg">(self, i, value)</span>
<span class="ansi-green-intense-fg ansi-bold">    134</span> 
<span class="ansi-green-intense-fg ansi-bold">    135</span>     <span class="ansi-green-fg">def</span> SetTensor<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> i<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 136</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> _tensorflow_wrap_interpreter_wrapper<span class="ansi-blue-fg">.</span>InterpreterWrapper_SetTensor<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> i<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    137</span> 
<span class="ansi-green-intense-fg ansi-bold">    138</span>     <span class="ansi-green-fg">def</span> GetTensor<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> i<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">ValueError</span>: Cannot set tensor: Got tensor of type 5 but expected type 3 for input 1 </pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Still, weird problem.  No luck?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># if failed, run twice</span>
<span class="n">itp_full</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">"example1.tflite"</span><span class="p">)</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">allocate_tensors</span><span class="p">()</span>
<span class="n">imgx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span> <span class="c1"># cast to uint8</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">imgx</span><span class="p">)</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>
<span class="n">res</span><span class="o">=</span>  <span class="n">itp_full</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[8]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[255, 255, 255]], dtype=uint8)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>What just happened?   Any clue is more than welcome!</p>
<p>OK, let's decipher the output.  As we are in the wild of the TF documentation, I will briefly summarize the conversion - Long story short, here is the thing:</p>
<p>$ f = \frac{i-m}{s}, \text{ or } i = f\times s+m$</p>
<p>where $f$ is the float value (what you need), $i$ is the quantized value (what output), and $s,m$ are <code>quantization</code> value in the <code>get_output_details</code>.  <strong>Notice the order, it is $s,m$</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">v</span> <span class="o">=</span> <span class="n">itp_full</span><span class="o">.</span><span class="n">get_output_details</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'quantization'</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="p">(</span><span class="n">res</span><span class="o">-</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># expect to see [3,3,3]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>(0.0117647061124444, 0)
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt output_prompt">Out[0]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[3.00000006, 3.00000006, 3.00000006]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The above conversion is also explained in the <a href="https://www.tensorflow.org/lite/performance/post_training_quantization#representation_for_quantized_tensors">post-training-quantization</a>,</p>
<p>Great, it seems that we finished our job.<br>
Think for one more second, did we miss something?  What happens if the input/output is outside of the above scope, or if our input is in range of $[0,1]$ when as the network is trained?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">itp_full</span><span class="o">.</span><span class="n">allocate_tensors</span><span class="p">()</span>
<span class="n">imgx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span> <span class="c1"># cast to uint8</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">imgx</span><span class="p">)</span>
<span class="n">itp_full</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>
<span class="n">res</span><span class="o">=</span>  <span class="n">itp_full</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">itp_full</span><span class="o">.</span><span class="n">get_output_details</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'quantization'</span><span class="p">]</span>
<span class="p">(</span><span class="n">res</span><span class="o">-</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># float-percision result should be [0,2,4] !!</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[0]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[3.00000006, 2.00000004, 3.00000006]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The right way is to set the <code>quantized_input_stats()</code> correspondingly.
However, it is fairly misleading with the "mean, std_dev" appended in the tutorial...</p>
<p>Until I found out that they actually the <code>mean_values</code>and <code>std_dev_values</code> in <a href="https://www.tensorflow.org/lite/convert/cmdline_reference">command line reference</a> with the true math formula attached.</p>
<p>And another piece of a potential problem - notice that the order of the <code>quantization</code> is $s,m$, whereas, in the <code>quantized_input_stats</code>, they are $m',s'$.  And their relation is:</p>
<p>$s'=1/s, m=m'$.</p>
<p>If you felt confusing, take this, your original input data $f$ is in the range $f_{min}$, $f_{max}$, and you want to map them into $[0,255]$, therefore:</p>
<p>$s' = \frac{255}{f_{max}-f_{min}}$</p>
<p>and</p>
<p>$m = -f_{min}/s'$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">"img"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="n">const</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
  <span class="n">val</span> <span class="o">=</span> <span class="n">img</span> <span class="o">+</span> <span class="n">const</span>
  <span class="n">out</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'output'</span><span class="p">)</span> <span class="c1"># tf.fake_quant_with_min_max_args(val, min=0., max=1., name="output")</span>

  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">converter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">TFLiteConverter</span><span class="o">.</span><span class="n">from_session</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="p">[</span><span class="n">img</span><span class="p">],</span> <span class="p">[</span><span class="n">out</span><span class="p">])</span>
    <span class="n">converter</span><span class="o">.</span><span class="n">inference_type</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="n">QUANTIZED_UINT8</span>
    <span class="n">input_arrays</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">get_input_arrays</span><span class="p">()</span>
    <span class="n">converter</span><span class="o">.</span><span class="n">quantized_input_stats</span> <span class="o">=</span> <span class="p">{</span><span class="n">input_arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mf">127.</span><span class="p">)}</span>  <span class="c1"># mean, std_dev</span>
    <span class="n">converter</span><span class="o">.</span><span class="n">default_ranges_stats</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">tflite_model</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">convert</span><span class="p">()</span>
    <span class="nb">open</span><span class="p">(</span><span class="s2">"example2.tflite"</span><span class="p">,</span> <span class="s2">"wb"</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">tflite_model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">itp_pruned</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">Interpreter</span><span class="p">(</span><span class="n">model_path</span><span class="o">=</span><span class="s2">"example2.tflite"</span><span class="p">)</span>
<span class="n">v_input</span> <span class="o">=</span> <span class="n">itp_pruned</span><span class="o">.</span><span class="n">get_input_details</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'quantization'</span><span class="p">]</span>
<span class="n">v_output</span> <span class="o">=</span> <span class="n">itp_pruned</span><span class="o">.</span><span class="n">get_output_details</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="s1">'quantization'</span><span class="p">]</span>
<span class="n">imgx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]])</span>
<span class="n">imgb</span> <span class="o">=</span> <span class="p">(</span><span class="n">imgx</span> <span class="o">/</span> <span class="n">v_input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">v_input</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>

<span class="n">itp_pruned</span><span class="o">.</span><span class="n">allocate_tensors</span><span class="p">()</span>
<span class="n">itp_pruned</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">imgb</span><span class="p">)</span>
<span class="n">itp_pruned</span><span class="o">.</span><span class="n">invoke</span><span class="p">()</span>
<span class="n">res</span><span class="o">=</span>  <span class="n">itp_pruned</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="p">(</span><span class="n">res</span><span class="o">-</span><span class="n">v_output</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">*</span><span class="n">v_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># float-percision result should be [1.1, 2.1, 3.1]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[0]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([[1.09411767, 2.09411769, 3.00000006]])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we successfully recover the first two values.  And I believe that you can also figure out that the last value is clipped by 3, which is defined in <code>converter.default_ranges_stats = (0, 3)</code> in the previous block.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Last but not the least, the <a href="https://www.tensorflow.org/lite/performance/post_training_quantization">tutorial</a> also fails -</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [0]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">converter</span><span class="o">.</span><span class="n">optimizations</span> <span class="o">=</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">lite</span><span class="o">.</span><span class="n">Optimize</span><span class="o">.</span><span class="n">OPTIMIZE_FOR_SIZE</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AttributeError</span>                            Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-42-c2316bf03cdb&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>converter<span class="ansi-blue-fg">.</span>optimizations <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">[</span>tf<span class="ansi-blue-fg">.</span>lite<span class="ansi-blue-fg">.</span>Optimize<span class="ansi-blue-fg">.</span>OPTIMIZE_FOR_SIZE<span class="ansi-blue-fg">]</span>

<span class="ansi-red-fg">AttributeError</span>: module 'tensorflow._api.v1.lite' has no attribute 'Optimize'</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Summary">Summary<a class="anchor-link" href="#Summary">¶</a>
</h3>
<p>The well-documented first-half of tutorial intrigued me to try TensorFlow Lite, however, the second half makes me feeling like taught to sail on land and throw to a boat in the Pacific ocean directly.  With this journey, I want to highlight a couple problems to use TensorFlow from scratch.  The problems are not limited to TF Lite, they also represent the majority types of problems I encountered daily with Tensorflow.</p>
<ol>
<li>Version consistency - Although it is getting better to enforce version compatibility, TensorFlow is still poor in that aspect. Could TF provide an installation matrix similar <a href="https://pytorch.org/get-started/locally/">PyTorch</a> to simplify the installation process?</li>
<li>Documentation - The documentation needs further cleanup and improve.  Don't just provide a link to the source code. A good example in TF looks like <a href="https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter">TFLiteConverter</a>.  Not only contains explanations, but also provide examples.  And bad one like <a href="https://www.tensorflow.org/api_docs/python/tf/initializers/global_variables">this</a> points to another function without a URL.</li>
<li>Be more specific on type hint.  TensorFlow is complicated due to the behind-the-scene computational graph.  It is even worse as we got lost about the expected input and correct order to execute things (e.g. Session, Graph, Namespace, etc.).  It is crucial to document the input type and the explanation correspondingly for each function.</li>
<li>Clean out-dated documentation.  Along with the version control,  the mismatch between the code and documentation is still surprisingly bad.  For instance, we failed to access the optimize variable in the latest tutorial with the latest version. </li>
<li>Create a friendly Stack Overflow community.  Just check the issue page of TensorFlow on GitHub.  How many questions are directed to Stack Overflow? But how many questions and solutions on the Stack Overflow are outdated?  The pain to using TF is also tightly linked with the difficulty to find a suitable solution.  Given the scale of Google, it should not be a challenge to maintain a good community with reliable solutions.  If problems are always directed to other parties without reliable solutions, users will probably leave the tool for other replacement. </li>
</ol>
<h3 id="Acknowledgement">Acknowledgement<a class="anchor-link" href="#Acknowledgement">¶</a>
</h3>
<p>I want to thank Google providing the <a href="https://colab.research.google.com">colab</a> for free.  Without it, I cannot easily get Tensorflow and CUDA work coherently without any trouble.</p>

</div>
</div>
</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul class="pager hidden-print">
<li class="previous">
                <a href="../tensoflow-profiling/" rel="prev" title="TensorFlow Profiling">Previous post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comments</h2>
        
        
<div id="fb-root"></div>
<script>
  window.fbAsyncInit = function() {
    // init the FB JS SDK
    FB.init({
      appId      : '321809675046639',
      status     : true,
      xfbml      : true
    });

  };

  // Load the SDK asynchronously
  (function(d, s, id){
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) {return;}
     js = d.createElement(s); js.id = id;
     js.src = "https://connect.facebook.net/en_US/all.js";
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script><div class="fb-comments" data-href="https://jiayiliu.github.com/posts/tensoflow-lite/" data-width="470"></div>


        </section><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script></article><div id="fb-root"></div>
<script>
    // thank lxml for this
    $('.fb-comments-count').each(function(i, obj) {
        var url = obj.attributes['data-url'].value;
        // change here if you dislike the default way of displaying
        // this
        obj.innerHTML = '<fb:comments-count href="' + url + '"></fb:comments-count> comments';
    });

  window.fbAsyncInit = function() {
    // init the FB JS SDK
    FB.init({
      appId      : '321809675046639',
      status     : true,
      xfbml      : true
    });

  };

  // Load the SDK asynchronously
  (function(d, s, id){
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) {return;}
     js = d.createElement(s); js.id = id;
     js.src = "https://connect.facebook.net/en_US/all.js";
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script><!--End of body content--><footer id="footer">
            Contents © 2019         <a href="mailto:jiayi.uiuc@gmail.com">Jiayi (Jason) Liu</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-128364527-2"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-128364527-2');
</script>
</body>
</html>
