{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-lite-explore.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "nikola": {
      "category": "Tensorflow",
      "date": "2019-05-25 17:13:01 UTC-08:00",
      "description": "Tensorflow Lite, and reflection on Tensorflow Usability",
      "link": "",
      "slug": "tensoflow-lite",
      "tags": "",
      "title": "Reflection on Tensorflow Documentation by a short user journey",
      "type": "text"
  }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mv8A4HEpFFG",
        "colab_type": "text"
      },
      "source": [
        "# Reflection on Tensorflow Documentation by a short user journey\n",
        "\n",
        "Tensorflow community keeps improving to address  [problems with Tensorflow](http://nicodjimenez.github.io/2017/10/08/tensorflow.html).\n",
        "\n",
        "At the time of TF 2.0 release, I sitll found it is very painful to follow the TF documentation to get things done.  Here I write down some random notes during my short journey to use TF Lite for the quantization. Also I hope this tour can guide some other people to find an easier life when use TF.",
        "<!-- TEASER_END -->\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4uZDIdqUMnc",
        "colab_type": "code",
        "outputId": "5f56d024-f110-4ee9-8aab-616f29aeb985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "earFc_L1lEtc",
        "colab_type": "text"
      },
      "source": [
        "## Honeymoon\n",
        "\n",
        "The first glance of the TF Lite [documentation](https://www.tensorflow.org/lite/convert/python_api) delights me by its well-organized structure and detailed documentation. \n",
        "\n",
        "I followed the tutorial on the model conversion without worrying about [the different ways of saving a TF model](https://www.reddit.com/r/MachineLearning/comments/6nupas/p_tensorflow_whats_the_best_way_to_saverestore/).  And quickly, I got what I want - save a quantized model:\n",
        "\n",
        "```python\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\n",
        "  const = tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\n",
        "  val = img + const\n",
        "  out = tf.fake_quant_with_min_max_args(val, min=0., max=1., name=\"output\")\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    converter = tf.lite.TFLiteConverter.from_session(sess, [img], [out])\n",
        "    converter.inference_type = tf.lite.constants.QUANTIZED_UINT8\n",
        "    input_arrays = converter.get_input_arrays()\n",
        "    converter.quantized_input_stats = {input_arrays[0] : (0., 1.)}  # mean, std_dev\n",
        "    tflite_model = converter.convert()\n",
        "    open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
        " ```\n",
        " \n",
        " Now, the pain starts - I could not find a solution to restore the quantized model to produce the right prediction!\n",
        "\n",
        "And during my exploration on solving the challenge (yes, it is a challenge given the many misleading and confusing messages in the official documentation), I even start wondering whether TF community welcome users or it is just a propaganda tool for Google and no true intention for sharing.\n",
        "\n",
        "Now let me show you my user journey towards the evil side of TF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFaHuKPOqog5",
        "colab_type": "text"
      },
      "source": [
        "## A simplified model, but wait ...\n",
        "\n",
        "OK, the first step, let me use a simpler model as follows,  a vector with a dimension of $1\\times3$ adds to a constant vector $[1,2,3]$.   \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaA2DW7rsfla",
        "colab_type": "code",
        "outputId": "ba87a34a-15c7-415c-c9e0-8b55b9931194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "  img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 3))\n",
        "  const = tf.constant([1., 2., 3.])\n",
        "  val = img + const\n",
        "  out = tf.fake_quant_with_min_max_args(val, min=0., max=1., name=\"output\")\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    v = sess.run(out, {img:[[1,2,3]]})\n",
        "v"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7fhiM8Dbr2U",
        "colab_type": "text"
      },
      "source": [
        "OK, a quick glance hints the problem of the `fake_quant_with_min_max_args()`. Why using it in the origin code esp. the constants are all larger than 1?\n",
        "Further digging into the documentation, I found there are 6 different functions all start with `fake_quant_with_min_max`.  If you are interested in understanding how to use them properly, follow the [official documentation](https://www.tensorflow.org/api_docs/python/tf/quantization/quantize) or check the [stack-overflow explanation](https://stackoverflow.com/questions/50524897/what-are-the-differences-between-tf-fake-quant-with-min-max-args-and-tf-fake-qua).\n",
        "\n",
        "I will skip it for now, as my goal is to recover the quantized model first.  And a quantized output with 0 and 1 clearly increases my difficulty to debug (or reduce the chance to find a bug).\n",
        "\n",
        "For now, I replace it with an identity function and label the output name correspondingly.  And because that, I add `default_ranges_stats` in below to quantify the range of the internal values, (see [reference](https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/lite/python/lite.py))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SJzwoeXUY_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "  img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 3))\n",
        "  const = tf.constant([1., 2., 3.])\n",
        "  val = img + const\n",
        "  out = tf.identity(val, name='output') # tf.fake_quant_with_min_max_args(val, min=0., max=1., name=\"output\")\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    converter = tf.lite.TFLiteConverter.from_session(sess, [img], [out])\n",
        "    converter.inference_type = tf.lite.constants.QUANTIZED_UINT8\n",
        "    input_arrays = converter.get_input_arrays()\n",
        "    converter.quantized_input_stats = {input_arrays[0] : (0, 1.)}  # mean, std_dev\n",
        "    converter.default_ranges_stats = (0, 3)\n",
        "    tflite_model = converter.convert()\n",
        "    open(\"example1.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMvcSHD8mzo2",
        "colab_type": "text"
      },
      "source": [
        "Originally, I searched for how to restore the model in Python under the [Inference](https://www.tensorflow.org/lite/guide/inference), but the reality is that it is only available under the [Python API section](https://www.tensorflow.org/lite/convert/python_api#using_the_interpreter_from_model_data_)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkv_cBVMpb4f",
        "colab_type": "code",
        "outputId": "89242b73-6637-4097-9ed1-aa3e456f6771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "itp_full = tf.lite.Interpreter(model_path=\"example1.tflite\")\n",
        "itp_full.allocate_tensors()\n",
        "itp_full.get_input_details(), itp_full.get_output_details()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([{'dtype': numpy.uint8,\n",
              "   'index': 1,\n",
              "   'name': 'img',\n",
              "   'quantization': (1.0, 0),\n",
              "   'shape': array([1, 3], dtype=int32)}],\n",
              " [{'dtype': numpy.uint8,\n",
              "   'index': 2,\n",
              "   'name': 'output',\n",
              "   'quantization': (0.0117647061124444, 0),\n",
              "   'shape': array([1, 3], dtype=int32)}])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqdiWbpFYrgP",
        "colab_type": "code",
        "outputId": "983dc7f8-7e08-4b67-e2a6-8c701e63ecd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "imgx = [[2,1,0]]\n",
        "itp_full.set_tensor(1, imgx)\n",
        "itp_full.invoke()\n",
        "res=  itp_full.get_tensor(2)\n",
        "res"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-138418d20125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mitp_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mitp_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0mitp_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36mset_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    173\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0mcould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mset\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mresize_tensor_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\u001b[0m in \u001b[0;36mSetTensor\u001b[0;34m(self, i, value)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mSetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensorflow_wrap_interpreter_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreterWrapper_SetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mGetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Got tensor of type 4 but expected type 3 for input 1 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6N2MuHHvboz",
        "colab_type": "text"
      },
      "source": [
        "Comparing with the `input_details` in the previous block, it is might be clear to the reader already that the type is wrong.  But could TF kindly provide the type without any reference to find what's the hack the type 3 and 4 are???\n",
        "\n",
        "A simple search guides me to this [issue](https://github.com/tensorflow/tensorflow/issues/22409) which states the type \" internal TFLite type casted from C++ type\".  Fine, but still no clue on what are the...\n",
        "And beneath that, [Onetaken](https://github.com/tensorflow/tensorflow/issues/22409#issuecomment-432484940) provided a URL, which leads to 404..  \n",
        "\n",
        "Fine, I can spend an hour to dig into the details, but let's get back to the theme of this article - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAubsKBnhj28",
        "colab_type": "code",
        "outputId": "4ac43d53-9060-44c8-9798-ad1364da570b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "imgx = np.array([[2,1,0]]).astype(np.uint8) # cast to uint8\n",
        "itp_full.set_tensor(1, imgx)\n",
        "itp_full.invoke()\n",
        "res=  itp_full.get_tensor(2)\n",
        "res"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-11989c7451e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# cast to uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mitp_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mitp_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0mitp_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0munderlying\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0mfails\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36m_ensure_safe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mform\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mBe\u001b[0m \u001b[0msure\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0monly\u001b[0m \u001b[0mhold\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0myou\u001b[0m \u001b[0mare\u001b[0m \u001b[0musing\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       data access.\"\"\")\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_tensor_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: There is at least 1 reference to internal data\n      in the interpreter in the form of a numpy array or slice. Be sure to\n      only hold the function returned from tensor() if you are using raw\n      data access."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnwfkadJxtb9",
        "colab_type": "text"
      },
      "source": [
        "What's the problem??   It follows the [official documentation](https://www.tensorflow.org/lite/convert/python_api#using_the_interpreter_from_a_model_file_)  Anyway, found a solution on [Stack Overflow](https://stackoverflow.com/questions/54006031/tf-lite-model-test-fails-with-run-time-error)\n",
        "\n",
        "Again, could TF documentation be more specific on the expected type of `set_tensor()`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW--qiCmY4tn",
        "colab_type": "code",
        "outputId": "a517cbae-ec27-41e5-a2c3-c0fc0db12043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "imgx = tf.convert_to_tensor([[2,1,0]], np.uint8) # cast to uint8\n",
        "itp_full.set_tensor(1, imgx)\n",
        "itp_full.invoke()\n",
        "res=  itp_full.get_tensor(2)\n",
        "res"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-da5825085942>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# cast to uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mitp_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mitp_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m=\u001b[0m  \u001b[0mitp_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36mset_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    173\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0mcould\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mset\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mresize_tensor_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\u001b[0m in \u001b[0;36mSetTensor\u001b[0;34m(self, i, value)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mSetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensorflow_wrap_interpreter_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreterWrapper_SetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mGetTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Got tensor of type 5 but expected type 3 for input 1 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXkBZVM7zpxn",
        "colab_type": "text"
      },
      "source": [
        "Still, weird problem.  No luck?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP8n0eukxrRy",
        "colab_type": "code",
        "outputId": "7f569f23-b587-47c5-e944-14e7c1668e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# if failed, run twice\n",
        "itp_full = tf.lite.Interpreter(model_path=\"example1.tflite\")\n",
        "itp_full.allocate_tensors()\n",
        "imgx = np.array([[2,1,0]]).astype(np.uint8) # cast to uint8\n",
        "itp_full.set_tensor(1, imgx)\n",
        "itp_full.invoke()\n",
        "res=  itp_full.get_tensor(2)\n",
        "res"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[255, 255, 255]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hhZXEBh0NAp",
        "colab_type": "text"
      },
      "source": [
        "What just happened?   Any clue is more than welcome!\n",
        "\n",
        "OK, let's decipher the output.  As we are in the wild of the TF documentation, I will briefly summarize the conversion - Long story short, here is the thing:\n",
        "\n",
        "$ f = \\frac{i-m}{s}, \\text{ or } i = f\\times s+m$\n",
        "\n",
        "where $f$ is the float value (what you need), $i$ is the quantized value (what output), and $s,m$ are `quantization` value in the `get_output_details`.  **Notice the order, it is $s,m$**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OntJ5P3_1VwV",
        "colab_type": "code",
        "outputId": "4258e62d-1900-45b6-b93a-a6d32ae4c80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "v = itp_full.get_output_details()[0]['quantization']\n",
        "print(v)\n",
        "(res-v[1])*v[0]  # expect to see [3,3,3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.0117647061124444, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.00000006, 3.00000006, 3.00000006]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8oUtntd2Tn2",
        "colab_type": "text"
      },
      "source": [
        "The above conversion is also explained in the [post-training-quantization](https://www.tensorflow.org/lite/performance/post_training_quantization#representation_for_quantized_tensors), \n",
        "\n",
        "Great, it seems that we finished our job.  \n",
        "Think for one more second, did we miss something?  What happens if the input/output is outside of the above scope, or if our input is in range of $[0,1]$ when as the network is trained?   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t1bhaot8feY",
        "colab_type": "code",
        "outputId": "ad685600-f77b-4c25-ef4e-9724ecf4bfbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "itp_full.allocate_tensors()\n",
        "imgx = np.array([[-1,0,1]]).astype(np.uint8) # cast to uint8\n",
        "itp_full.set_tensor(1, imgx)\n",
        "itp_full.invoke()\n",
        "res=  itp_full.get_tensor(2)\n",
        "v = itp_full.get_output_details()[0]['quantization']\n",
        "(res-v[1])*v[0]  # float-percision result should be [0,2,4] !!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.00000006, 2.00000004, 3.00000006]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWRrC2EE7dn2",
        "colab_type": "text"
      },
      "source": [
        "The right way is to set the `quantized_input_stats()` correspondingly.\n",
        "However, it is fairly misleading with the \"mean, std_dev\" appended in the tutorial...\n",
        "\n",
        "Until I found out that they actually the `mean_values`and `std_dev_values` in [command line reference](https://www.tensorflow.org/lite/convert/cmdline_reference) with the true math formula attached.\n",
        "\n",
        "And another piece of a potential problem - notice that the order of the `quantization` is $s,m$, whereas, in the `quantized_input_stats`, they are $m',s'$.  And their relation is:\n",
        "\n",
        "$s'=1/s, m=m'$.\n",
        "\n",
        "\n",
        "If you felt confusing, take this, your original input data $f$ is in the range $f_{min}$, $f_{max}$, and you want to map them into $[0,255]$, therefore:\n",
        "\n",
        "$s' = \\frac{255}{f_{max}-f_{min}}$\n",
        "\n",
        "and\n",
        "\n",
        "$m = -f_{min}/s'$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuxONTOB2TC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Graph().as_default():\n",
        "  img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 3))\n",
        "  const = tf.constant([1., 2., 3.])\n",
        "  val = img + const\n",
        "  out = tf.identity(val, name='output') # tf.fake_quant_with_min_max_args(val, min=0., max=1., name=\"output\")\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    converter = tf.lite.TFLiteConverter.from_session(sess, [img], [out])\n",
        "    converter.inference_type = tf.lite.constants.QUANTIZED_UINT8\n",
        "    input_arrays = converter.get_input_arrays()\n",
        "    converter.quantized_input_stats = {input_arrays[0] : (128, 127.)}  # mean, std_dev\n",
        "    converter.default_ranges_stats = (0, 3)\n",
        "    tflite_model = converter.convert()\n",
        "    open(\"example2.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3OqyuZVZ_A3",
        "colab_type": "code",
        "outputId": "62c6cfef-0fd5-48b8-d151-e0488b4d21f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "itp_pruned = tf.lite.Interpreter(model_path=\"example2.tflite\")\n",
        "v_input = itp_pruned.get_input_details()[0]['quantization']\n",
        "v_output = itp_pruned.get_output_details()[0]['quantization']\n",
        "imgx = np.array([[0.1, 0.1, 0.1]])\n",
        "imgb = (imgx / v_input[0] + v_input[1]).astype(np.uint8)\n",
        "\n",
        "itp_pruned.allocate_tensors()\n",
        "itp_pruned.set_tensor(1, imgb)\n",
        "itp_pruned.invoke()\n",
        "res=  itp_pruned.get_tensor(2)\n",
        "(res-v_output[1])*v_output[0]  # float-percision result should be [1.1, 2.1, 3.1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.09411767, 2.09411769, 3.00000006]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHVMP4US9W7O",
        "colab_type": "text"
      },
      "source": [
        "Now we successfully recover the first two values.  And I believe that you can also figure out that the last value is clipped by 3, which is defined in `converter.default_ranges_stats = (0, 3)` in the previous block."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIsp21BOsumg",
        "colab_type": "text"
      },
      "source": [
        "Last but not the least, the [tutorial](https://www.tensorflow.org/lite/performance/post_training_quantization) also fails - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmpSEadcdvTh",
        "colab_type": "code",
        "outputId": "847abe2c-d01c-4eb8-a983-43f52fc27595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-c2316bf03cdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZE_FOR_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v1.lite' has no attribute 'Optimize'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPwSGlvnmrH3",
        "colab_type": "text"
      },
      "source": [
        "## Summary\n",
        "\n",
        "The well-documented first-half of tutorial intrigued me to try TensorFlow Lite, however, the second half makes me feeling like taught to sail on land and throw to a boat in the Pacific ocean directly.  With this journey, I want to highlight a couple problems to use TensorFlow from scratch.  The problems are not limited to TF Lite, they also represent the majority types of problems I encountered daily with Tensorflow.\n",
        "\n",
        "1. Version consistency - Although it is getting better to enforce version compatibility, TensorFlow is still poor in that aspect. Could TF provide an installation matrix similar [PyTorch](https://pytorch.org/get-started/locally/) to simplify the installation process?\n",
        "2. Documentation - The documentation needs further cleanup and improve.  Don't just provide a link to the source code. A good example in TF looks like [TFLiteConverter](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter).  Not only contains explanations, but also provide examples.  And bad one like [this](https://www.tensorflow.org/api_docs/python/tf/initializers/global_variables) points to another function without a URL.\n",
        "3. Be more specific on type hint.  TensorFlow is complicated due to the behind-the-scene computational graph.  It is even worse as we got lost about the expected input and correct order to execute things (e.g. Session, Graph, Namespace, etc.).  It is crucial to document the input type and the explanation correspondingly for each function.\n",
        "4. Clean out-dated documentation.  Along with the version control,  the mismatch between the code and documentation is still surprisingly bad.  For instance, we failed to access the optimize variable in the latest tutorial with the latest version. \n",
        "5. Create a friendly Stack Overflow community.  Just check the issue page of TensorFlow on GitHub.  How many questions are directed to Stack Overflow? But how many questions and solutions on the Stack Overflow are outdated?  The pain to using TF is also tightly linked with the difficulty to find a suitable solution.  Given the scale of Google, it should not be a challenge to maintain a good community with reliable solutions.  If problems are always directed to other parties without reliable solutions, users will probably leave the tool for other replacement. \n",
        "\n",
        "## Acknowledgement\n",
        "\n",
        "I want to thank Google providing the [colab](https://colab.research.google.com) for free.  Without it, I cannot easily get Tensorflow and CUDA work coherently without any trouble."
      ]
    }
  ]
}